{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import math\n",
    "    \n",
    "class CoPreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x,x1, **kwargs):\n",
    "        return self.fn(self.norm(x),self.norm(x1), **kwargs)\n",
    "\n",
    "class CoAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x,x1):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "        qkv1 = self.to_qkv(x1).chunk(3, dim = -1)\n",
    "        q1, k1, v1 = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv1)\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k1) * self.scale\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "        \n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v1)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class CoTransformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                CoPreNorm(dim, CoAttention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))]))\n",
    "\n",
    "    def forward(self, x,x1):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x,x1) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)\n",
    "    \n",
    "class cosa(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = in_channels * patch_size ** 2\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b t c (h p1) (w p2) -> b (t c) (h w) (p1 p2)', p1 = patch_size, p2 = patch_size),\n",
    "        )\n",
    "        self.pos_embedding = PositionalEmbedding(num_patches*patch_size**2)\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.transformer = CoTransformer(patch_size**2, depth, heads, dim_head, dim*scale_dim, dropout)\n",
    "        self.img_out = image_size\n",
    "        self.time = num_frames\n",
    "        self.channel = in_channels\n",
    "        self.patch_size = patch_size\n",
    "    def forward(self, x1,x2):\n",
    "        x1,x2 = rearrange(x1, 'b c t n d -> b t c n d'), rearrange(x2, 'b c t n d -> b t c n d')\n",
    "        x1,x2 = self.to_patch_embedding(x1),self.to_patch_embedding(x2)\n",
    "        b, t, n, d = x1.shape\n",
    "        pos1,pos2 = self.pos_embedding(x1,n,d),self.pos_embedding(x2,n,d)\n",
    "        x1 = x1 + pos1\n",
    "        x2 = x2 + pos2\n",
    "        x1 = rearrange(x1, 'b t n d -> (b t) n d')\n",
    "        x2 = rearrange(x2, 'b t n d -> (b t) n d')\n",
    "        x = self.transformer(x1,x2)\n",
    "        patch_height = int(self.img_out/self.patch_size)\n",
    "        x = rearrange(x, '(t c) (ph pw) (p1 p2) -> t c (ph p1) (pw p2)', t = self.time, c = self.channel,\n",
    "                      ph = patch_height, p1 = self.patch_size)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = rearrange(x, 'b t c n d -> b c t n d')\n",
    "        return x\n",
    "    \n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x_attn = attn(x) \n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x),self.norm(x_attn)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, demb):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "\n",
    "        self.demb = demb\n",
    "        self.mlp = nn.Sequential(nn.LayerNorm(self.demb),nn.Linear(self.demb, 1))\n",
    "        inv_freq = 1 / (10 ** (torch.arange(0.0, demb, 2.0) / demb))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, pos_seq,imgsize,imgdim, bsz=None):\n",
    "        pos_seq = rearrange(pos_seq, 'b t n d -> b t (n d)')\n",
    "        pos_seq = self.mlp(pos_seq)\n",
    "        pos_seq = pos_seq.squeeze(0)\n",
    "        pos_seq = pos_seq.squeeze(1)\n",
    "        #print(pos_seq)\n",
    "        sinusoid_inp = torch.ger(pos_seq, self.inv_freq)\n",
    "        pos_emb = torch.cat([torch.sin(sinusoid_inp), torch.cos(sinusoid_inp)], dim=-1)\n",
    "        if bsz is not None:\n",
    "            pos_emb = pos_emb[:,None,:].expand(-1, bsz, -1)\n",
    "        else:\n",
    "            pos_emb = pos_emb[:,None,:]\n",
    "        #print(pos_emb.shape)\n",
    "        pos_emb = rearrange(pos_emb, 't b (n d) -> b t n d',n=imgsize,d=imgdim)\n",
    "        return pos_emb\n",
    "    \n",
    "class STFH(nn.Module):\n",
    "    def __init__(self, image_size,patch_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = in_channels * patch_size ** 2\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b t c (h p1) (w p2) -> b (t c) (h w) (p1 p2)', p1 = patch_size, p2 = patch_size),\n",
    "        )\n",
    "        self.pos_embedding = PositionalEmbedding(num_patches*patch_size**2)\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.spatio_temporal_transformer = Transformer(patch_size**2, depth, heads, dim_head, dim*scale_dim, dropout)\n",
    "        self.img_out = image_size\n",
    "        self.time = num_frames\n",
    "        self.channel = in_channels\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "       \n",
    "    def forward(self, x):\n",
    "        #print('before p_emb',x.shape)\n",
    "        theta = 5\n",
    "        pool = nn.MaxPool3d(kernel_size=theta, stride=1, padding=(theta - 1) // 2)\n",
    "        x_pool = pool(x)\n",
    "        x = 2*x - x_pool\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        x = self.to_patch_embedding(x)\n",
    "        b, t, n, d = x.shape\n",
    "        pos = self.pos_embedding(x,n,d)\n",
    "        x = x + pos\n",
    "        x = self.dropout(x)\n",
    "        x = rearrange(x, 'b t n d -> (b t) n d')\n",
    "        x,x_att = self.spatio_temporal_transformer(x)\n",
    "        patch_height = int(self.img_out/self.patch_size)\n",
    "        x = rearrange(x, '(t c) (ph pw) (p1 p2) -> t c (ph p1) (pw p2)', t = self.time, c = self.channel,\n",
    "                      ph = patch_height, p1 = self.patch_size)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = rearrange(x, 'b t c n d -> b c t n d')\n",
    "        x_att = rearrange(x_att, '(t c) (ph pw) (p1 p2) -> t c (ph p1) (pw p2)', t = self.time, c = self.channel,\n",
    "                      ph = patch_height, p1 = self.patch_size)\n",
    "        x_att = x_att.unsqueeze(0)\n",
    "        x_att = rearrange(x_att, 'b t c n d -> b c t n d')\n",
    "        return x,x_att\n",
    "    \n",
    "class Dual_path(nn.Module):\n",
    "    def __init__(self, image_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        #assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        #num_patches = (image_size // patch_size) ** 2\n",
    "        #patch_dim = in_channels * patch_size ** 2\n",
    "        self.spatio_stfh = STFH(image_size=image_size, patch_size=image_size//2, in_channels=in_channels ,num_frames=num_frames)\n",
    "        self.temporal_stfh = STFH(image_size=image_size, patch_size=image_size, in_channels=in_channels ,num_frames=num_frames)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #print('before p_emb',x.shape)\n",
    "        theta = 5\n",
    "        pool = nn.MaxPool3d(kernel_size=theta, stride=1, padding=(theta - 1) // 2)\n",
    "        x_pool = pool(x)\n",
    "        x_bound = 2*x - x_pool\n",
    "        x_bound,x_att_b = self.spatio_stfh(x_bound)\n",
    "        x,x_att_t = self.temporal_stfh(x)\n",
    "        x_croatt = x_att_t*x_att_b\n",
    "        x = x+x_bound+x_croatt\n",
    "        return x\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer, time_steps):        \n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.layers = nn.ModuleList([layer for i in range(time_steps)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        batch_size, time_steps, C, H, W = x.size()\n",
    "        output = torch.tensor([]).cuda()\n",
    "        #output = torch.tensor([])\n",
    "        for i in range(time_steps):\n",
    "            output_t = self.layers[i](x[:, i, :, :, :])\n",
    "            output_t  = output_t.unsqueeze(1)\n",
    "            output = torch.cat((output, output_t ), 1)\n",
    "        output = rearrange(output, 'b t c n d -> b c t n d')\n",
    "        return output\n",
    "\n",
    "\n",
    "class EncoderBottleneck3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, base_width=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=[1,2,2], bias=False),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "        )\n",
    "\n",
    "        width = int(out_channels * (base_width / 64))\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(width, width, kernel_size=3, stride=[1,2,2], groups=1, padding=1, dilation=1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(width, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_down = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = x + x_down\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim,seq_frame):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=7, stride=[1,2,2], padding=3, bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.encoder1 = EncoderBottleneck3d(out_channels, out_channels * 2, stride=2)\n",
    "        self.encoder2 = EncoderBottleneck3d(out_channels * 2, out_channels * 4, stride=2)\n",
    "        self.encoder3 = EncoderBottleneck3d(out_channels * 4, out_channels * 8, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(out_channels * 8, out_channels * 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm2 = nn.BatchNorm3d(out_channels * 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b t c n d -> b c t n d')\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x1 = self.relu(x)\n",
    "        x2 = self.encoder1(x1)\n",
    "        x3 = self.encoder2(x2)\n",
    "        x = self.encoder3(x3)\n",
    "        #x = rearrange(x, \"b t (h w) c ->b t c h w\",h = 8, w=8)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "        #x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        #x1_out = rearrange(x1_out, 'b c t n d -> b t c n d')\n",
    "        #x2_out = rearrange(x2_out, 'b c t n d -> b t c n d')\n",
    "        #x3_out = rearrange(x3_out, 'b c t n d -> b t c n d')\n",
    "        return x, x1, x2, x3\n",
    "\n",
    "class DecoderBottleneck3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,seq_frame, scale_factor=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = TimeDistributed(nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=True), time_steps = seq_frame)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False))\n",
    "\n",
    "    def forward(self, x, x_concat=None):\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "\n",
    "        if x_concat is not None:\n",
    "            x = torch.cat([x_concat, x], dim=1)\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "class dconv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,d_rate, stride=1, base_width=64):\n",
    "        super().__init__()\n",
    "\n",
    "        width = int(out_channels * (base_width / 64))\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(width, width, kernel_size=3, stride=[1,1,1], groups=1, padding=d_rate, dilation=d_rate, bias=False)\n",
    "        self.norm2 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(width, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class task_specific_decoder(nn.Module):\n",
    "    def __init__(self, out_channels, class_num, drop_rate,seq_frame):\n",
    "        super().__init__()\n",
    "        self.d_rate = drop_rate\n",
    "        self.decoder1 = DecoderBottleneck3d(out_channels * 8, out_channels * 2,seq_frame)\n",
    "        self.decoder2 = DecoderBottleneck3d(out_channels * 4, out_channels,seq_frame)\n",
    "        self.dropout = TimeDistributed(torch.nn.Dropout(p=self.d_rate),time_steps = seq_frame)\n",
    "        \n",
    "    def forward(self, x, x2, x3):\n",
    "        x = self.decoder1(x, x3)\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder2(x, x2)\n",
    "        #x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        return x\n",
    "\n",
    "    \n",
    "class segment_head(nn.Module):\n",
    "    def __init__(self, out_channels, class_num, drop_rate,seq_frame):\n",
    "        super().__init__()\n",
    "        self.decoder3 = DecoderBottleneck3d(out_channels * 2, int(out_channels * 1 / 2),seq_frame)\n",
    "        self.decoder4 = DecoderBottleneck3d(int(out_channels * 1 / 2), int(out_channels * 1 / 8),seq_frame)\n",
    "        self.conv1 = nn.Conv3d(int(out_channels * 1 / 8), class_num, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, x1):\n",
    "        x = self.decoder3(x, x1)\n",
    "        x = self.decoder4(x)\n",
    "        x = self.conv1(x)\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        return x\n",
    "\n",
    "class point_head(nn.Module):\n",
    "    def __init__(self, out_channels, class_num, seq_frame,height,weight):\n",
    "        super().__init__()\n",
    "        self.seq_frame = seq_frame\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        self.decoder3 = DecoderBottleneck3d(out_channels * 2, int(out_channels * 1 / 2),seq_frame)\n",
    "        self.decoder4 = DecoderBottleneck3d(int(out_channels * 1 / 2), int(out_channels * 1 / 8),seq_frame)\n",
    "        self.conv1 = nn.Conv3d(int(out_channels * 1 / 8), class_num, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(class_num,1, kernel_size=1)\n",
    "        self.mlp_out = nn.Sequential(\n",
    "            nn.LayerNorm(self.height*self.weight),\n",
    "            nn.Linear(self.height*self.weight, 2))\n",
    "        \n",
    "    def forward(self, x, x1):\n",
    "        x = self.decoder3(x, x1)\n",
    "        x = self.decoder4(x)\n",
    "        x = self.conv1(x)\n",
    "        x_map = self.conv2(x)\n",
    "        x_map = rearrange(x_map, 'b c t n d -> b t c n d')\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        x_pot = rearrange(x, 'b t c n d -> b t c (n d)')\n",
    "        x_pot = self.mlp_out(x_pot)\n",
    "        return x_pot,x_map\n",
    "\n",
    "# class classifi_head(nn.Module):\n",
    "#     def __init__(self, out_channels, class_num,seq_frame):\n",
    "#         super().__init__()\n",
    "#         self.out_ch = out_channels\n",
    "#         self.class_num = class_num\n",
    "#         self.seq_frame = seq_frame\n",
    "#         self.avgpool = nn.AvgPool2d(32, stride=1)\n",
    "#         self.fc = nn.Linear(self.out_ch,self.class_num)\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "#     def forward(self,x):\n",
    "#         x = x[:,:,0,:,:]\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "    \n",
    "class frame_head(nn.Module):\n",
    "    def __init__(self, out_channels, class_num,seq_frame):\n",
    "        super().__init__()\n",
    "        self.out_ch = out_channels\n",
    "        self.class_num = class_num\n",
    "        self.seq_frame = seq_frame\n",
    "        self.dconv3d2 = dconv3d(self.out_ch*1, self.out_ch*2, d_rate = 3, stride=2)\n",
    "        self.avgpool2d2  = TimeDistributed(nn.AdaptiveAvgPool2d(8), time_steps = seq_frame)\n",
    "        self.dconv3d3 = dconv3d(self.out_ch*2, self.out_ch*4, d_rate = 2, stride=2)\n",
    "        self.avgpool2d3  = TimeDistributed(nn.AdaptiveAvgPool2d(2), time_steps = seq_frame)\n",
    "        self.dconv3d4 = dconv3d(self.out_ch*4, self.out_ch*8, d_rate = 1, stride=2)\n",
    "        self.avgpool2d4  = TimeDistributed(nn.AdaptiveAvgPool2d(1), time_steps = seq_frame)\n",
    "        self.mlp_out = nn.Sequential(\n",
    "            nn.LayerNorm(self.out_ch*8),\n",
    "            nn.Linear(self.out_ch*8, self.class_num))\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x = self.dconv3d2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool2d2(x)\n",
    "        x = self.dconv3d3(x)\n",
    "        x = self.avgpool2d3(x)\n",
    "        x = self.dconv3d4(x)\n",
    "        x = self.avgpool2d4(x)\n",
    "        #print(x.shape)\n",
    "        x = rearrange(x, 'b t c n d -> (c n d)(b t)')\n",
    "        x_reg = self.mlp_out(x)\n",
    "        x_reg.squeeze()\n",
    "        #x_reg = rearrange(x_reg, 'n s -> s n')\n",
    "        return x_reg\n",
    "    \n",
    "class TaskAttention(nn.Module):\n",
    "    def __init__(self, in_ch, ratio=16):\n",
    "        super(TaskAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv3d(in_ch*2, in_ch//16, kernel_size=1),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv3d(in_ch // 16, in_ch*2, kernel_size=1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv3 = nn.Conv3d(in_ch*2, in_ch, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm3d(in_ch)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x1,x2):\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        x = self.sigmoid(out)+x\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class pattern_strcture(nn.Module):\n",
    "    def __init__(self, image_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        self.spatio_stfh = STFH(image_size=image_size, patch_size=image_size//4, in_channels=in_channels ,num_frames=num_frames)\n",
    "        self.ta = TaskAttention(in_channels)\n",
    "        size = 32\n",
    "        self.cosa = cosa(image_size=size,patch_size=int(size//2), in_channels=32 ,num_frames=30)\n",
    "       \n",
    "    def forward(self,x1,x2,x3):\n",
    "        x1_sa,x_att_b1 = self.spatio_stfh(x1)\n",
    "        #print(self.ta(x2,x3,x4).shape)\n",
    "        x2_sa,x_att_b2 = self.spatio_stfh(x2)\n",
    "        #print(x1.shape,x2.shape,x3.shape,x4.shape)\n",
    "        x3_sa,x_att_b3 = self.spatio_stfh(x3)\n",
    "        # x4_sa,x_att_b4 = self.spatio_stfh(x4)\n",
    "        beta = 0.1\n",
    "        # x1 = beta*self.ta(x2_sa,x3_sa)+(1-beta)*x1_sa\n",
    "        # x2 = beta*self.ta(x1_sa,x3_sa)+(1-beta)*x2_sa\n",
    "        # x3 = beta*self.ta(x2_sa,x1_sa)+(1-beta)*x3_sa\n",
    "        #print(self.ta(x2_sa,x3_sa).shape,x1_sa.shape)\n",
    "        #cosa\n",
    "        x1 = self.cosa(beta*self.ta(x2_sa,x3_sa),(1-beta)*x1_sa)\n",
    "        x2 = self.cosa(beta*self.ta(x1_sa,x3_sa),(1-beta)*x2_sa)\n",
    "        x3 = self.cosa(beta*self.ta(x2_sa,x1_sa),(1-beta)*x3_sa)\n",
    "        # x1 = x1_sa\n",
    "        # x2 = x2_sa\n",
    "        # x3 = x3_sa\n",
    "        # x4 = beta*self.ta(x2_sa,x3_sa,x1_sa)+(1-beta)*x4_sa\n",
    "        return x1,x2,x3\n",
    "\n",
    "seq_frame = 30\n",
    "\n",
    "class Multivit_net(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim, class_num, drop_rate,seq_frame\n",
    "                 ,mode,height,weight):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(img_dim, in_channels, out_channels,\n",
    "                               head_num, mlp_dim, block_num, patch_dim,seq_frame)\n",
    "        self.seg_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        self.pot_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        self.frm_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        # self.cls_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        self.seg_head = segment_head(out_channels, class_num, drop_rate,seq_frame)\n",
    "        # self.cls_head = classifi_head(out_channels, class_num=4,seq_frame=seq_frame)\n",
    "        self.pot_head = point_head(out_channels, class_num=4,seq_frame=seq_frame,height=height,weight=weight)\n",
    "        self.frm_head = frame_head(out_channels, class_num=3,seq_frame=seq_frame)\n",
    "        self.mode = mode\n",
    "        self.stps = pattern_strcture(image_size=int(img_dim/4), in_channels=out_channels ,num_frames=seq_frame)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x1, x2, x3 = self.encoder(x)\n",
    "        if self.mode == 'seg':\n",
    "            x_seg = self.seg_decoder(x, x2, x3)\n",
    "            x_seg = self.seg_head(x_seg,x1)\n",
    "            return x_seg\n",
    "        elif self.mode == 'pot':\n",
    "            x_pot = self.pot_decoder(x, x2, x3)\n",
    "            x_pot = self.pot_head(x_pot,x1)\n",
    "            return x_pot\n",
    "        elif self.mode == 'frm':\n",
    "            x_frm = self.frm_decoder(x, x2, x3)\n",
    "            x_frm = self.frm_head(x_frm)\n",
    "            return x_frm\n",
    "        # elif self.mode == 'cls':\n",
    "        #     x_cls = self.cls_decoder(x, x2, x3)\n",
    "        #     x_cls = self.cls_head(x_cls)\n",
    "            return x_cls\n",
    "        elif self.mode == 'mtl':\n",
    "            x_seg = self.seg_decoder(x, x2, x3)\n",
    "            x_pot = self.pot_decoder(x, x2, x3)\n",
    "            x_frm = self.frm_decoder(x, x2, x3)\n",
    "            # x_cls = self.cls_decoder(x, x2, x3)\n",
    "            #print(x_seg.shape)\n",
    "            x_seg,x_pot,x_frm = self.stps(x_seg,x_pot,x_frm)\n",
    "            x_seg = self.seg_head(x_seg,x1)\n",
    "            x_pot,x_potmap = self.pot_head(x_pot,x1)\n",
    "            x_frm = self.frm_head(x_frm)\n",
    "            # x_cls = self.cls_head(x_cls)\n",
    "        return x_pot,x_potmap,x_frm,x_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# device=('cuda')\n",
    "# conv = Multivit_net(img_dim=128,in_channels=1,out_channels=128,head_num=4,mlp_dim=512,\n",
    "#                     block_num=8,patch_dim=16,class_num=1,drop_rate = 0.1,seq_frame=30,mode = 'mtl',height=128,weight=128).to(device)\n",
    "# size = 128\n",
    "# a = torch.randn(1, 30, 1, size, size).to(device)\n",
    "# with torch.no_grad():\n",
    "#     b,b1,b2,b3,b4 = conv(a)\n",
    "#     #torch.tanh(b)\n",
    "#     print(b.shape,b1.shape)\n",
    "# # print(b_reg.shape,b_cls.shape)#torch.Size([3,30]) torch.Size([1, 4])\n",
    "# # y = torch.randint(5, (30, 1, 2)).float().to(device)\n",
    "# # crit = torch.nn.SmoothL1Loss()\n",
    "# # print(b)\n",
    "# # print(y)\n",
    "# # print(crit(b, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import morphology\n",
    "def coefficients(gt, pred, smooth=1e-12):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = torch.gt(pred, 0.5)\n",
    "    pred = pred.type(torch.float32)\n",
    "    intersection = torch.sum(gt * pred)\n",
    "    gt, pred = torch.sum(gt), torch.sum(pred)\n",
    "    union = gt + pred - intersection\n",
    "\n",
    "    precision = intersection / (pred + smooth)\n",
    "    recall = intersection / (gt + smooth)\n",
    "\n",
    "    beta_square = 0.3\n",
    "    f_beta_coeff = (1 + beta_square) * precision * recall / (beta_square * precision + recall + smooth)\n",
    "    dice_coeff = (2. * intersection) / (union + intersection + smooth)\n",
    "    jaccard_coeff = intersection / (union + smooth)\n",
    "    return dice_coeff, jaccard_coeff, f_beta_coeff\n",
    "\n",
    "def get_hausdorff(gt, pred, sampling=0.3, connectivity=1):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = torch.gt(pred, 0.5)\n",
    "    input1 = gt\n",
    "    input2 = pred\n",
    "    input1 = np.array(input1.cpu().clone()) \n",
    "    input2 = np.array(input2.cpu().clone()) \n",
    "    input_1 = np.atleast_1d(input1.astype(np.bool))\n",
    "    input_2 = np.atleast_1d(input2.astype(np.bool))\n",
    "\n",
    "    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n",
    "\n",
    "    S = input_1 ^ morphology.binary_erosion(input_1, conn)\n",
    "    Sprime = input_2 ^ morphology.binary_erosion(input_2, conn)\n",
    "\n",
    "    dta = morphology.distance_transform_edt(~S, sampling)\n",
    "    dtb = morphology.distance_transform_edt(~Sprime, sampling)\n",
    "\n",
    "    sds = np.concatenate([np.ravel(dta[Sprime != 0]), np.ravel(dtb[S != 0])])\n",
    "    hausdorff_distance = sds.max()\n",
    "    mean_abs_distance = np.abs(sds).mean()\n",
    "    return hausdorff_distance, mean_abs_distance\n",
    "    \n",
    "def seg_loss(y_pred,y_true):\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    smooth       = 1e-12\n",
    "    y_true_back  = 1 - y_true\n",
    "    y_pred_back  = 1 - y_pred\n",
    "    alpha        = 1 / (torch.pow(torch.sum(y_true), 2) + smooth)\n",
    "    beta         = 1 / (torch.pow(torch.sum(y_true_back), 2) + smooth)\n",
    "    numerater    = alpha * torch.sum(y_true * y_pred) + beta * torch.sum(y_true_back * y_pred_back)\n",
    "    denominator  = alpha * torch.sum(y_true + y_pred) + beta * torch.sum(y_true_back + y_pred_back)\n",
    "    dice_loss    = 1 - (2. * numerater) / (denominator + smooth)\n",
    "    mae_loss     = torch.mean(torch.log(1 + torch.exp(torch.abs(y_pred - y_true))))\n",
    "    w            = (img_size * img_size - torch.sum(y_pred)) / (torch.sum(y_pred) + smooth)\n",
    "    key_w        = 0.003\n",
    "    crossentropy = - torch.mean(key_w * w * y_true * torch.log(y_pred + smooth) + y_true_back * torch.log(y_pred_back + smooth))\n",
    "    #print(crossentropy)\n",
    "    return crossentropy + dice_loss + mae_loss\n",
    "\n",
    "def one_hot(label, n_classes, requires_grad=True):\n",
    "    \"\"\"Return One Hot Label\"\"\"\n",
    "    divce = label.device\n",
    "    one_hot_label = torch.eye(n_classes, device=device, requires_grad=requires_grad)[label]\n",
    "    one_hot_label = one_hot_label.transpose(1, 3).transpose(2, 3)\n",
    "    return one_hot_label\n",
    "\n",
    "def boundary_cos_loss(gt , pred):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    #gt dimension (B,T,C,H,W)\n",
    "    b,t,c,h,w = gt.shape\n",
    "    for i in range(t):\n",
    "        gt_frame = gt[0,i:i+1,:,:,:]\n",
    "        pred_frame = pred[0,i:i+1,:,:,:]\n",
    "        theta0 = 3\n",
    "        gt_cont = F.max_pool2d(1 - gt_frame, kernel_size=theta0, stride=1, padding=(theta0 - 1) // 2)\n",
    "        gt_cont -= 1 - gt_frame\n",
    "        pred_cont = F.max_pool2d(1 - pred_frame, kernel_size=theta0, stride=1, padding=(theta0 - 1) // 2)\n",
    "        pred_cont -= 1 - pred_frame\n",
    "        sim = torch.cosine_similarity(gt_cont.squeeze(0).squeeze(0),pred_cont.squeeze(0).squeeze(0))\n",
    "        sim_norm = torch.sum(sim)/(h)\n",
    "        sim_loss = 1 - sim_norm*2\n",
    "        if i == 0:\n",
    "            loss = sim_loss\n",
    "        else:\n",
    "            loss = loss + sim_loss\n",
    "    return loss / t\n",
    "\n",
    "def corr_loss(pred,gt):\n",
    "    pred_lva,pred_mvd,pred_lvd = pred[0,:],pred[1,:],pred[2,:]\n",
    "    gt_lva,  gt_mvd,  gt_lvd   = gt[0,:],  gt[1,:],  gt[2,:]\n",
    "    pred,gt = pred_lva, gt_lva\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lva = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / ((\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2)))+1e-12)\n",
    "    pred,gt = pred_mvd, gt_mvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_mvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / ((\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2)))+1e-12)\n",
    "    pred,gt = pred_lvd, gt_lvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / ((\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2)))+1e-12)\n",
    "    #print('corr1:',corr_lva,'corr2:',corr_mvd,'corr3:',corr_lvd)\n",
    "    corr = corr_lva+2*corr_mvd+2*corr_lvd+1e-12\n",
    "    return 5-corr\n",
    "\n",
    "def mae_loss(pred,gt):\n",
    "    mae1 = torch.mean(torch.abs(pred[0,:]-gt[0,:]))\n",
    "    mae2 = torch.mean(torch.abs(pred[1,:]-gt[1,:]))\n",
    "    mae3 = torch.mean(torch.abs(pred[2,:]-gt[2,:]))\n",
    "    mae = mae2+mae3*2\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    #logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    mae_mean = torch.mean(torch.abs(torch.mean(pred)-torch.mean(gt)))\n",
    "    return mae\n",
    "\n",
    "def mae_point(pred,gt):\n",
    "    mae = torch.mean(torch.abs(pred-gt))\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    return mae\n",
    "\n",
    "def mae_cal(pred,gt):\n",
    "    mae1 = torch.mean(torch.abs(pred[0,:]-gt[0,:]))\n",
    "    mae2 = torch.mean(torch.abs(pred[1,:]-gt[1,:]))\n",
    "    mae3 = torch.mean(torch.abs(pred[2,:]-gt[2,:]))\n",
    "    mae = mae2+mae3*2\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def person_corr(pred, gt):#皮尔森相关系数\n",
    "    pred_lva,pred_mvd,pred_lvd = pred[0,:],pred[1,:],pred[2,:]\n",
    "    gt_lva,  gt_mvd,  gt_lvd   = gt[0,:],  gt[1,:],  gt[2,:]\n",
    "    pred,gt = pred_lva, gt_lva\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lva = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / (\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2))+1e-12)\n",
    "    pred,gt = pred_mvd, gt_mvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_mvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / (\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2))+1e-12)\n",
    "    pred,gt = pred_lvd, gt_lvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / (\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2))+1e-12)\n",
    "    return corr_lva, corr_mvd,corr_lvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============load nature===============\n",
      "==============load hmc===============\n",
      "==============load camus===============\n",
      "==============load lm===============\n",
      "==============load mx===============\n",
      "==============load sz===============\n"
     ]
    }
   ],
   "source": [
    "#traning set\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy.matlib\n",
    "def landmark(center_x,center_y,IMAGE_HEIGHT, IMAGE_WIDTH):\n",
    "    R = np.sqrt(2**2 + 2**2)\n",
    "    Gauss_map = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    # 直接利用矩阵运算实现\n",
    "    mask_x = np.matlib.repmat(center_x, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    mask_y = np.matlib.repmat(center_y, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    x1 = np.arange(IMAGE_WIDTH)\n",
    "    x_map = np.matlib.repmat(x1, IMAGE_HEIGHT, 1)\n",
    "    y1 = np.arange(IMAGE_HEIGHT)\n",
    "    y_map = np.matlib.repmat(y1, IMAGE_WIDTH, 1)\n",
    "    y_map = np.transpose(y_map)\n",
    "    Gauss_map = np.sqrt((x_map-mask_x)**2+(y_map-mask_y)**2)\n",
    "    Gauss_map = np.exp(-0.5*Gauss_map/R)\n",
    "    return Gauss_map\n",
    "\n",
    "def locmap(pot):\n",
    "    gauss_batch = []\n",
    "    for i in range(0,pot.shape[0]):\n",
    "        gauss_tp = []\n",
    "        for j in range(0,pot.shape[1]):\n",
    "            g_map1 = landmark(pot[i, j, 0, 0],pot[i, j, 0, 1],128,128)\n",
    "            g_map2 = landmark(pot[i, j, 1, 0],pot[i, j, 1, 1],128,128)\n",
    "            g_map3 = landmark(pot[i, j, 2, 0],pot[i, j, 2, 1],128,128)\n",
    "            g_map4 = landmark(pot[i, j, 3, 0],pot[i, j, 3, 1],128,128)\n",
    "            Gauss_map = (g_map1+g_map2+g_map3+g_map4)/4\n",
    "            gauss_tp.append(Gauss_map)\n",
    "        gauss_batch.append(gauss_tp)\n",
    "    gauss_batch = np.array(gauss_batch)[:, :, :, :, np.newaxis]\n",
    "    return gauss_batch\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/nature_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 1800\n",
    "nat_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_1.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "nat_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_1.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "nat_a4c_cls  = 4*np.ones((train_set_up))\n",
    "nat_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_1.npy')[train_set_down:train_set_up, :]\n",
    "nat_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_1.npy')[train_set_down:train_set_up, :]\n",
    "nat_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_1.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load nature===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/HMC_QU_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 100\n",
    "hmc_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_hmc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "hmc_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_hmc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "hmc_a4c_cls  = 4*np.ones((train_set_up))\n",
    "hmc_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_hmc.npy')[train_set_down:train_set_up, :]\n",
    "hmc_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_hmc.npy')[train_set_down:train_set_up, :]\n",
    "hmc_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_hmc.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load hmc===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/camus_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 500\n",
    "camus_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a2c_cls  = 2*np.ones((train_set_up))\n",
    "camus_a4c_cls  = 4*np.ones((train_set_up))\n",
    "camus_a2c_pot  = np.load(data_path + '/' + 'pot_a2c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a2c_frm  = np.load(data_path + '/' + 'frm_a2c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_camus.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load camus===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/lm_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 122\n",
    "lm_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a3c_ims  = np.load(data_path + '/' + 'ims_a3c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a3c_gts  = np.load(data_path + '/' + 'gts_a3c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a2c_cls  = 2*np.ones((train_set_up))\n",
    "lm_a3c_cls  = 3*np.ones((train_set_up))\n",
    "lm_a4c_cls  = 4*np.ones((train_set_up))\n",
    "lm_a2c_pot  = np.load(data_path + '/' + 'pot_a2c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a3c_pot  = np.load(data_path + '/' + 'pot_a3c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a3c_potmap  = np.load(data_path + '/' + 'potmap_a3c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a2c_frm  = np.load(data_path + '/' + 'frm_a2c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a3c_frm  = np.load(data_path + '/' + 'frm_a3c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_lm.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load lm===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/mx_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 80\n",
    "mx_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a3c_ims  = np.load(data_path + '/' + 'ims_a3c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a3c_gts  = np.load(data_path + '/' + 'gts_a3c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a2c_cls  = 2*np.ones((train_set_up))\n",
    "mx_a3c_cls  = 3*np.ones((train_set_up))\n",
    "mx_a4c_cls  = 4*np.ones((train_set_up))\n",
    "mx_a2c_pot  = np.load(data_path + '/' + 'pot_a2c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a3c_pot  = np.load(data_path + '/' + 'pot_a3c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a3c_potmap  = np.load(data_path + '/' + 'potmap_a3c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a2c_frm  = np.load(data_path + '/' + 'frm_a2c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a3c_frm  = np.load(data_path + '/' + 'frm_a3c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_mx.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load mx===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/szkid'\n",
    "train_set_down = 0\n",
    "train_set_up = 80\n",
    "sz_a2c_ims  = np.load(data_path + '/' + 'ims_a2c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a3c_ims  = np.load(data_path + '/' + 'ims_a3c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a4c_ims  = np.load(data_path + '/' + 'ims_a4c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_asc_ims  = np.load(data_path + '/' + 'ims_asc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a2c_gts  = np.load(data_path + '/' + 'gts_a2c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a3c_gts  = np.load(data_path + '/' + 'gts_a3c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a4c_gts  = np.load(data_path + '/' + 'gts_a4c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_asc_gts  = np.load(data_path + '/' + 'gts_asc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_out_gts  = np.load(data_path + '/' + 'gts_out.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a2c_cls  = 2*np.ones((train_set_up))\n",
    "sz_a3c_cls  = 3*np.ones((train_set_up))\n",
    "sz_a4c_cls  = 4*np.ones((train_set_up))\n",
    "sz_asc_cls  = 1*np.ones((train_set_up))\n",
    "sz_a2c_pot  = np.load(data_path + '/' + 'pot_a2c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a3c_pot  = np.load(data_path + '/' + 'pot_a3c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a4c_pot  = np.load(data_path + '/' + 'pot_a4c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a3c_potmap  = np.load(data_path + '/' + 'potmap_a3c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a2c_frm  = np.load(data_path + '/' + 'frm_a2c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a3c_frm  = np.load(data_path + '/' + 'frm_a3c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a4c_frm  = np.load(data_path + '/' + 'frm_a4c.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load sz===============')\n",
    "\n",
    "# ims         = np.concatenate((hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "#                               lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims, sz_asc_ims), axis=0)\n",
    "# gts         = np.concatenate((hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "#                               lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts, sz_out_gts), axis=0)\n",
    "# clss         = np.concatenate((hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "#                              lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls, sz_asc_cls), axis=0)\n",
    "# ims         = np.concatenate((hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "#                               lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "# gts         = np.concatenate((hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "#                               lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "# clss        = np.concatenate((hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "#                               lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "# reg         = np.concatenate((hmc_a4c_reg,camus_a2c_reg, camus_a4c_reg,mx_a2c_reg, mx_a3c_reg, mx_a4c_reg,\n",
    "#                               lm_a2c_reg, lm_a3c_reg, lm_a4c_reg,sz_a2c_reg, sz_a3c_reg, sz_a4c_reg), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366, 30, 128, 128, 1) (366, 30, 128, 128, 1) (366,) (366, 30, 4, 2) (366, 30, 128, 128, 1) (366, 30)\n"
     ]
    }
   ],
   "source": [
    "data_mode = 'lm'\n",
    "if data_mode == 'psax':\n",
    "    ims         = np.concatenate((sz_a2c_ims, sz_a3c_ims, sz_a4c_ims, sz_asc_ims), axis=0)\n",
    "    gts         = np.concatenate((sz_a2c_gts, sz_a3c_gts, sz_a4c_gts, sz_out_gts), axis=0)\n",
    "    clss        = np.concatenate((sz_a2c_cls, sz_a3c_cls, sz_a4c_cls, sz_asc_cls), axis=0)\n",
    "    pot         = np.concatenate((sz_a2c_pot, sz_a3c_pot, sz_a4c_pot, sz_asc_pot), axis=0)\n",
    "    frm         = np.concatenate((sz_a2c_frm, sz_a3c_frm, sz_a4c_frm, sz_asc_frm), axis=0)\n",
    "elif data_mode == 'apic_1':\n",
    "    ims         = np.concatenate((sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "    gts         = np.concatenate((sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "    clss        = np.concatenate((sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "    pot         = np.concatenate((sz_a2c_pot, sz_a3c_pot, sz_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((sz_a2c_potmap, sz_a3c_potmap, sz_a4c_potmap), axis=0)\n",
    "    frm         = np.concatenate((sz_a2c_frm, sz_a3c_frm, sz_a4c_frm), axis=0) \n",
    "elif data_mode == 'lm':\n",
    "    ims         = np.concatenate((lm_a2c_ims, lm_a3c_ims, lm_a4c_ims), axis=0)\n",
    "    gts         = np.concatenate((lm_a2c_gts, lm_a3c_gts, lm_a4c_gts), axis=0)\n",
    "    clss        = np.concatenate((lm_a2c_cls, lm_a3c_cls, lm_a4c_cls), axis=0)\n",
    "    pot         = np.concatenate((lm_a2c_pot, lm_a3c_pot, lm_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((lm_a2c_potmap, lm_a3c_potmap, lm_a4c_potmap), axis=0)\n",
    "    frm         = np.concatenate((lm_a2c_frm, lm_a3c_frm, lm_a4c_frm), axis=0)\n",
    "elif data_mode == 'mx':\n",
    "    ims         = np.concatenate((mx_a2c_ims, mx_a3c_ims, mx_a4c_ims), axis=0)\n",
    "    gts         = np.concatenate((mx_a2c_gts, mx_a3c_gts, mx_a4c_gts), axis=0)\n",
    "    clss        = np.concatenate((mx_a2c_cls, mx_a3c_cls, mx_a4c_cls), axis=0)\n",
    "    pot         = np.concatenate((mx_a2c_pot, mx_a3c_pot, mx_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((mx_a2c_potmap, mx_a3c_potmap, mx_a4c_potmap), axis=0)\n",
    "    frm         = np.concatenate((mx_a2c_frm, mx_a3c_frm, mx_a4c_frm), axis=0)\n",
    "elif data_mode == 'apic_2':\n",
    "    ims         = np.concatenate((hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "                                  lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "    print(ims.shape)\n",
    "    gts         = np.concatenate((hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "                                  lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "    print(gts.shape)\n",
    "    clss        = np.concatenate((hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "                                  lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "    print(clss.shape)\n",
    "    pot         = np.concatenate((hmc_a4c_pot,camus_a2c_pot, camus_a4c_pot,mx_a2c_pot, mx_a3c_pot, mx_a4c_pot,\n",
    "                                  lm_a2c_pot, lm_a3c_pot, lm_a4c_pot,sz_a2c_pot, sz_a3c_pot, sz_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((hmc_a4c_potmap,camus_a2c_potmap, camus_a4c_potmap,mx_a2c_potmap, mx_a3c_potmap, mx_a4c_potmap,\n",
    "                                  lm_a2c_potmap, lm_a3c_potmap, lm_a4c_potmap,sz_a2c_potmap, sz_a3c_potmap, sz_a4c_potmap), axis=0)\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = np.concatenate((hmc_a4c_frm,camus_a2c_frm, camus_a4c_frm,mx_a2c_frm, mx_a3c_frm, mx_a4c_frm,\n",
    "                                  lm_a2c_frm, lm_a3c_frm, lm_a4c_frm,sz_a2c_frm, sz_a3c_frm, sz_a4c_frm), axis=0) \n",
    "elif data_mode == 'nat':\n",
    "    ims         = np.concatenate((nat_a4c_ims,hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "                                  lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "    print(ims.shape)\n",
    "    gts         = np.concatenate((nat_a4c_gts,hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "                                  lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "    print(gts.shape)\n",
    "    clss        = np.concatenate((nat_a4c_cls,hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "                                  lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "    print(clss.shape)\n",
    "    pot         = np.concatenate((nat_a4c_pot,hmc_a4c_pot,camus_a2c_pot, camus_a4c_pot,mx_a2c_pot, mx_a3c_pot, mx_a4c_pot,\n",
    "                                  lm_a2c_pot, lm_a3c_pot, lm_a4c_pot,sz_a2c_pot, sz_a3c_pot, sz_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((nat_a4c_potmap,hmc_a4c_potmap,camus_a2c_potmap, camus_a4c_potmap,mx_a2c_potmap, mx_a3c_potmap, mx_a4c_potmap,\n",
    "                                  lm_a2c_potmap, lm_a3c_potmap, lm_a4c_potmap,sz_a2c_potmap, sz_a3c_potmap, sz_a4c_potmap), axis=0)\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = np.concatenate((nat_a4c_frm,hmc_a4c_frm,camus_a2c_frm, camus_a4c_frm,mx_a2c_frm, mx_a3c_frm, mx_a4c_frm,\n",
    "                                  lm_a2c_frm, lm_a3c_frm, lm_a4c_frm,sz_a2c_frm, sz_a3c_frm, sz_a4c_frm), axis=0) \n",
    "    print(frm.shape) \n",
    "elif data_mode == 'nature':\n",
    "    ims         = nat_a4c_ims\n",
    "    print(ims.shape)\n",
    "    gts         = nat_a4c_gts\n",
    "    print(gts.shape)\n",
    "    clss        = nat_a4c_cls\n",
    "    print(clss.shape)\n",
    "    pot         = nat_a4c_pot\n",
    "    potmap      = nat_a4c_potmap\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = nat_a4c_frm\n",
    "    print(frm.shape)   \n",
    "elif data_mode == 'hmc':\n",
    "    ims         = hmc_a4c_ims\n",
    "    print(ims.shape)\n",
    "    gts         = hmc_a4c_gts\n",
    "    print(gts.shape)\n",
    "    clss        = hmc_a4c_cls\n",
    "    print(clss.shape)\n",
    "    pot         = hmc_a4c_pot\n",
    "    potmap      = hmc_a4c_potmap\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = hmc_a4c_frm\n",
    "    print(frm.shape) \n",
    "elif data_mode == 'camus':\n",
    "    ims         = camus_a4c_ims\n",
    "    print(ims.shape)\n",
    "    gts         = camus_a4c_gts\n",
    "    print(gts.shape)\n",
    "    clss        = camus_a4c_cls\n",
    "    print(clss.shape)\n",
    "    pot         = camus_a4c_pot\n",
    "    potmap      = camus_a4c_potmap\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = camus_a4c_frm\n",
    "    print(frm.shape) \n",
    "    \n",
    "# ims         = camus_a4c_ims\n",
    "# gts         = camus_a4c_gts\n",
    "#oe = OrdinalEncoder()\n",
    "#clss = oe.fit_transform(clss.reshape(-1, 1)).ravel()\n",
    "#clss = np.eye(4)[np.array(clss, dtype=np.int32)]\n",
    "print(ims.shape, gts.shape, clss.shape,pot.shape,potmap.shape,frm.shape)\n",
    "#ims = ims[:,:,:,:,:]\n",
    "#gts = gts[1:91,:,:,:,:]\n",
    "image = torch.from_numpy(ims)\n",
    "image = image.permute(0, 1, 4, 2, 3)\n",
    "label = torch.from_numpy(gts)\n",
    "label = label.permute(0, 1, 4, 2, 3)\n",
    "classi = torch.from_numpy(clss)\n",
    "point = torch.from_numpy(pot)\n",
    "pointmap = torch.from_numpy(potmap)\n",
    "pointmap = pointmap.permute(0, 1, 4, 2, 3)\n",
    "frame = torch.from_numpy(frm)\n",
    "#image = image[0:15, :, :,:,:]\n",
    "#label = label[0:15, :, :,:,:]\n",
    "# pi = np.random.permutation(image.shape[0])\n",
    "# image = image[pi, :, :,:,:]\n",
    "# label = label[pi, :, :,:,:]\n",
    "# classi = classi[pi]-1\n",
    "# point = point[pi]\n",
    "# pointmap = pointmap[pi]\n",
    "# frame = frame[pi]\n",
    "# #split train-test\n",
    "# sp = 2500\n",
    "# sup = 3600\n",
    "# image_test = image[sp:sup,:,:,:,:]\n",
    "# label_test = label[sp:sup,:,:,:,:]\n",
    "# classi_test = classi[sp:sup]\n",
    "# point_test = point[sp:sup,:,:]\n",
    "# pointmap_test = pointmap[sp:sup,:,:,:,:]\n",
    "# frame_test = frame[sp:sup,:]\n",
    "# image = image[:sp,:,:,:,:]\n",
    "# label = label[:sp:,:,:,:,:]\n",
    "# classi = classi[:sp]\n",
    "# pointmap = pointmap[:sp:,:,:,:,:]\n",
    "# frame = frame[:sp,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#traning set\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy.matlib\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch import nn, optim\n",
    "import timeit\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "import IPython.display\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "unloader = transforms.ToPILImage()\n",
    "\n",
    "def tensor_to_img(tensor_pred , data_num, frame_num,title=None):\n",
    "    #image = unloader(image)\n",
    "    #tensor_pred = tensor_pred.type(torch.float32)\n",
    "    #pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = tensor_pred\n",
    "    pred = unloader(pred)\n",
    "    #fig = plt.figure()\n",
    "    pred = np.array(pred)\n",
    "    pred = cv2.resize(pred, (256,256) , interpolation=cv2.INTER_AREA) \n",
    "    #plt.imshow(pred, cmap = 'gray')\n",
    "    return pred\n",
    "\n",
    "def tensor_to_lb(tensor_pred , data_num, frame_num,title=None):\n",
    "    #image = unloader(image)\n",
    "    tensor_pred = torch.sigmoid(tensor_pred)\n",
    "    tensor_pred = torch.gt(tensor_pred, 0.5)\n",
    "    tensor_pred = tensor_pred.type(torch.float32)\n",
    "    pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = unloader(pred)\n",
    "    #fig = plt.figure()\n",
    "    pred = np.array(pred)\n",
    "    pred = cv2.resize(pred, (256,256) , interpolation=cv2.INTER_AREA) \n",
    "    #plt.imshow(pred, cmap = 'gray')\n",
    "    return pred\n",
    "\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.4):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = cv2.Canny(mask.astype(np.uint8),0,1)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= 0.5,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= 0.5,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def fill_contour(img):\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    n = len(contours)  # 轮廓的个数\n",
    "    max_area = 0\n",
    "    for i  in range(n):\n",
    "        if cv2.contourArea(contours[i]) > max_area:\n",
    "            max_area = cv2.contourArea(contours[i])\n",
    "    cv_contours = []\n",
    "    if n != 1:\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area < max_area:\n",
    "                cv_contours.append(contour)\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                img[y:y + h, x:x + w] = 1\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return img\n",
    "\n",
    "def tensor_im(tensor_pred , data_num, frame_num,title=None):\n",
    "    #tensor_pred = torch.sigmoid(tensor_pred)\n",
    "    #tensor_pred = torch.gt(tensor_pred, 0.5)\n",
    "    tensor_pred = tensor_pred.type(torch.float32)\n",
    "    pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = unloader(pred)\n",
    "    pred = np.array(pred)\n",
    "    #plt.imshow(pred)\n",
    "    return pred\n",
    "    \n",
    "def tensor_save(tensor_pred , data_num, frame_num,title=None):\n",
    "    tensor_pred = torch.sigmoid(tensor_pred)\n",
    "    tensor_pred = torch.gt(tensor_pred, 0.5)\n",
    "    tensor_pred = tensor_pred.type(torch.float32)\n",
    "    pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = unloader(pred)\n",
    "    kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5, 5))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10, 10))\n",
    "    pred = np.array(pred)\n",
    "    pred = fill_contour(pred)\n",
    "    #plt.imshow(pred)\n",
    "    return pred\n",
    "\n",
    "def landmark(center_x,center_y,IMAGE_HEIGHT, IMAGE_WIDTH):\n",
    "    R = np.sqrt(1**1 + 1**1)\n",
    "    Gauss_map = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    # 直接利用矩阵运算实现\n",
    "    mask_x = np.matlib.repmat(center_x, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    mask_y = np.matlib.repmat(center_y, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    x1 = np.arange(IMAGE_WIDTH)\n",
    "    x_map = np.matlib.repmat(x1, IMAGE_HEIGHT, 1)\n",
    "    y1 = np.arange(IMAGE_HEIGHT)\n",
    "    y_map = np.matlib.repmat(y1, IMAGE_WIDTH, 1)\n",
    "    y_map = np.transpose(y_map)\n",
    "    Gauss_map = np.sqrt((x_map-mask_x)**2+(y_map-mask_y)**2)\n",
    "    Gauss_map = np.exp(-0.5*Gauss_map/R)\n",
    "    return Gauss_map\n",
    "\n",
    "def norm(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img -= np.mean(img)\n",
    "    img /= (np.std(img) + 1e-12)\n",
    "    return img\n",
    "    \n",
    "def locmap(pot):\n",
    "    gauss_batch = []\n",
    "    for i in range(0,pot.shape[0]):\n",
    "        gauss_tp = []\n",
    "        for j in range(0,pot.shape[1]):\n",
    "            g_map1 = landmark(pot[i, j, 0, 0],pot[i, j, 0, 1],128,128)\n",
    "            g_map2 = landmark(pot[i, j, 1, 0],pot[i, j, 1, 1],128,128)\n",
    "            g_map3 = landmark(pot[i, j, 2, 0],pot[i, j, 2, 1],128,128)\n",
    "            g_map4 = landmark(pot[i, j, 3, 0],pot[i, j, 3, 1],128,128)\n",
    "            Gauss_map = [g_map1,g_map2,g_map3,g_map4]\n",
    "            Gauss_map = norm(Gauss_map)\n",
    "            gauss_tp.append(Gauss_map)\n",
    "        gauss_batch.append(gauss_tp)\n",
    "    gauss_batch = np.array(gauss_batch)[:, :, :, :, :]\n",
    "    return gauss_batch\n",
    "\n",
    "def locmap1(pot):\n",
    "    gauss_batch = []\n",
    "    for i in range(0,pot.shape[0]):\n",
    "        gauss_tp = []\n",
    "        for j in range(0,pot.shape[1]):\n",
    "            g_map1 = landmark(pot[i, j-5, 0, 0],pot[i, j, 0, 1],128,128)\n",
    "            g_map2 = landmark(pot[i, j-5, 1, 0],pot[i, j, 1, 1],128,128)\n",
    "            g_map3 = landmark(pot[i, j-5, 2, 0],pot[i, j, 2, 1],128,128)\n",
    "            g_map4 = landmark(pot[i, j-5, 3, 0],pot[i, j, 3, 1],128,128)\n",
    "            Gauss_map = [g_map1,g_map2,g_map3,g_map4]\n",
    "            Gauss_map = norm(Gauss_map)\n",
    "            gauss_tp.append(Gauss_map)\n",
    "        gauss_batch.append(gauss_tp)\n",
    "    gauss_batch = np.array(gauss_batch)[:, :, :, :, :]\n",
    "    return gauss_batch\n",
    "\n",
    "def point_color(potmap):\n",
    "    image = np.zeros((128,128,3),dtype=int)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    color1 = [1,1,0]#黄右\n",
    "    color2 = [0,1,1]#蓝左\n",
    "    color3 = [1,0,1]#粉下\n",
    "    color4 = [1,0,0]#红上\n",
    "    alpha = 1\n",
    "    k = 10\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[0, :, :] >= k,alpha * color1[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[1, :, :] >= k,alpha * color2[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[2, :, :] >= k,alpha * color3[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[3, :, :] >= k,alpha * color4[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def point_image(potmap,image):\n",
    "    # image = np.zeros((128,128,3),dtype=int)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    color1 = [1,1,0]#黄右\n",
    "    color2 = [0,1,1]#蓝左\n",
    "    color3 = [1,0,1]#粉下\n",
    "    color4 = [1,0,0]#红上\n",
    "    alpha = 1\n",
    "    k = 10\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[0, :, :] >= k,alpha * color1[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[1, :, :] >= k,alpha * color2[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[2, :, :] >= k,alpha * color3[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(potmap[3, :, :] >= k,alpha * color4[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_mask(image, mask, color, alpha=0.4):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = cv2.Canny(mask.astype(np.uint8),0,1)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    # mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= 0.5,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= 0.5,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_mode='mtl'\n",
    "model1 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model1.load_state_dict(torch.load('./weight/mlt_weights_base.pth'),True)\n",
    "model1.train()\n",
    "model2 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model2.load_state_dict(torch.load('./weight/mlt_weights_constrain_only2.pth'),True)\n",
    "model2.train()\n",
    "size = 128\n",
    "ki = image.to(device)\n",
    "kg = label.to(device)\n",
    "kp = point.to(device)\n",
    "kf = frame.to(device)\n",
    "tp = 89+122*0 #89\n",
    "for i in range(tp,tp+1):\n",
    "    a = ki[i:i+1]\n",
    "    d = kg[i:i+1]\n",
    "    c = kp[i:i+1]\n",
    "    e = kf[i:i+1]\n",
    "    #plt.subplots(figsize=(15,40))\n",
    "    color_lvla = [(1,0,0),(1,1,0)]\n",
    "    with torch.no_grad():\n",
    "        b1,b2,b3,b4 = model1(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        b11,b12,b13,b14 = model2(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        for k in range(6):\n",
    "            j = k+60\n",
    "            plt.subplots(figsize=(15,20),constrained_layout=True)\n",
    "            plt.subplot(141)\n",
    "            # print('imshape',ims.shape)\n",
    "            img = ims[i,:,:,j,0]\n",
    "            alp,bet = 53,11\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "            plt.axis('off')\n",
    "            image_ori = np.zeros((30,128,3),dtype=int)\n",
    "            image_ori[:,:,0] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,1] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,2] = (img*alp+bet)[:,:]\n",
    "            plt.subplot(142)\n",
    "            # print(d.shape)\n",
    "            #黄右，蓝左，粉下，红上\n",
    "            # plt.imshow(img,cmap = 'gray')\n",
    "            # plt.scatter(c[0,:,2,1].cpu(),range(0,30),c='Purple',s=2,marker='+')\n",
    "            # plt.scatter(c[0,:,3,1].cpu(),range(0,30),c='red',s=2,marker='+')\n",
    "            gt = tensor_save(d[0,:,0,:,j].to(torch.float32),0,1)\n",
    "            gt = apply_mask(image_ori,gt,color_lvla[1])\n",
    "            plt.imshow(gt)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(143)\n",
    "            # plt.imshow(img,cmap = 'gray')\n",
    "            # plt.scatter(b11[0,:,2,1].cpu()+3,range(0,30),c='Purple',s=2,marker='+')\n",
    "            # plt.scatter(b11[0,:,3,1].cpu(),range(0,30),c='red',s=2,marker='+')\n",
    "            pred = tensor_save(b14[0,:,0,:,j].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            plt.imshow(pred)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(144)\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "            plt.scatter(b1[0,:,2,1].cpu(),range(0,30),c='purple',s=2,marker='+')\n",
    "            plt.scatter(b1[0,:,3,1].cpu(),range(0,30),c='red',s=2,marker='+')\n",
    "            # pred = tensor_save(b4[0,:,0,:,j].to(torch.float32),0,1)\n",
    "            # pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            # plt.imshow(pred)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image, mask, color, alpha=0.4):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = cv2.Canny(mask.astype(np.uint8),0,1)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    # mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= 0.5,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= 0.5,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "\n",
    "train_mode='mtl'\n",
    "model1 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model1.load_state_dict(torch.load('./weight/mlt_weights_base.pth'),True)\n",
    "model1.train()\n",
    "model2 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model2.load_state_dict(torch.load('./weight/mlt_weights_constrain_only2.pth'),True)\n",
    "model2.train()\n",
    "size = 128\n",
    "ki = image.to(device)\n",
    "kg = label.to(device)\n",
    "kp = point.to(device)\n",
    "kf = frame.to(device)\n",
    "tp = 89+122*0 #89\n",
    "for i in range(tp,tp+1):\n",
    "    a = ki[i:i+1]\n",
    "    d = kg[i:i+1]\n",
    "    c = kp[i:i+1]\n",
    "    e = kf[i:i+1]\n",
    "    #plt.subplots(figsize=(15,40))\n",
    "    color_lvla = [(1,0,0),(1,0,1)]\n",
    "    with torch.no_grad():\n",
    "        b1,b2,b3,b4 = model1(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        b11,b12,b13,b14 = model2(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        for k in range(6):\n",
    "            j = k+60\n",
    "            plt.subplots(figsize=(15,20),constrained_layout=True)\n",
    "            plt.subplot(141)\n",
    "            # print('imshape',ims.shape)\n",
    "            img = ims[i,:,:,j,0]\n",
    "            alp,bet = 53,11\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "            plt.axis('off')\n",
    "            image_ori = np.zeros((30,128,3),dtype=int)\n",
    "            image_ori[:,:,0] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,1] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,2] = (img*alp+bet)[:,:]\n",
    "            plt.subplot(142)\n",
    "            # print(d.shape)\n",
    "            #黄右，蓝左，粉下，红上\n",
    "            gt = tensor_save(d[0,:,0,j,:].to(torch.float32),0,1)\n",
    "            gt = apply_mask(image_ori,gt,color_lvla[1])\n",
    "            plt.imshow(gt)\n",
    "            # plt.imshow(img,cmap = 'gray')\n",
    "            # plt.scatter(c[0,:,0,0].cpu(),range(0,30),c='yellow',s=2,marker='+')\n",
    "            # plt.scatter(c[0,:,1,0].cpu(),range(0,30),c='lightblue',s=2,marker='+')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(143)\n",
    "            pred = tensor_save(b14[0,:,0,j,:].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            plt.imshow(pred)\n",
    "            # plt.imshow(img,cmap = 'gray')\n",
    "            # plt.scatter(b11[0,:,0,0].cpu(),range(0,30),c='yellow',s=2,marker='+')\n",
    "            # plt.scatter(b11[0,:,1,0].cpu(),range(0,30),c='lightblue',s=2,marker='+')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(144)\n",
    "            pred = tensor_save(b4[0,:,0,j,:].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            plt.imshow(pred)\n",
    "            # plt.imshow(img,cmap = 'gray')\n",
    "            # plt.scatter(b1[0,:,0,0].cpu(),range(0,30),c='yellow',s=2,marker='+')\n",
    "            # plt.scatter(b1[0,:,1,0].cpu(),range(0,30),c='lightblue',s=2,marker='+')\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def cal_area(src):\n",
    "    src[src > 0] = 1\n",
    "    src_area = np.sum(src)\n",
    "    return src_area\n",
    "\n",
    "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, show=False, ax=None):\n",
    "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    mph : {None, number}, optional (default = None)\n",
    "        detect peaks that are greater than minimum peak height.\n",
    "    mpd : positive integer, optional (default = 1)\n",
    "        detect peaks that are at least separated by minimum peak distance (in\n",
    "        number of data).\n",
    "    threshold : positive number, optional (default = 0)\n",
    "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "        in relation to their immediate neighbors.\n",
    "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "        for a flat peak, keep only the rising edge ('rising'), only the\n",
    "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "        flat peak (None).\n",
    "    kpsh : bool, optional (default = False)\n",
    "        keep peaks with same height even if they are closer than `mpd`.\n",
    "    valley : bool, optional (default = False)\n",
    "        if True (1), detect valleys (local minima) instead of peaks.\n",
    "    show : bool, optional (default = False)\n",
    "        if True (1), plot data in matplotlib figure.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "    Returns\n",
    "    -------\n",
    "    ind : 1D array_like\n",
    "        indeces of the peaks in `x`.\n",
    "    Notes\n",
    "    -----\n",
    "    The detection of valleys instead of peaks is performed internally by simply\n",
    "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
    "\n",
    "    The function can handle NaN's\n",
    "    See this IPython Notebook [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')   # 将输入的数据转换成1维数组，浮点型\n",
    "    if x.size < 3:          # 如果数组尺寸小于3，则返回空，表示没有波峰或波谷\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:      # 表示当求波谷时，先将所有数据取反\n",
    "        x = -x\n",
    "    # find indexes of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan - 1, indnan + 1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size - 1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind] - x[ind - 1], x[ind] - x[ind + 1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                       & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indexes by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "\n",
    "    if show:\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.nan\n",
    "        if valley:\n",
    "            x = -x\n",
    "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "    return ind\n",
    "\n",
    "def cal_keyframe(srcnpy,i):\n",
    "    #srcnpy = np.load(srcnpy_path)[:, :, :, :, np.newaxis]\n",
    "    #for i in range(srcnpy.shape[0]):\n",
    "    area = []\n",
    "    for k in range(srcnpy.shape[1]):\n",
    "        area1 = cal_area(srcnpy[0,k,:,:,:])\n",
    "        area.append(area1)\n",
    "    area = np.array(area)\n",
    "    # area = area - np.mean(area)\n",
    "    # area = area/np.std(area)\n",
    "    area_avg = np.mean(area)\n",
    "    peak_h = detect_peaks(area,mph=np.mean(area), mpd=len(area)/5,edge='both')\n",
    "    peak_l = detect_peaks(area,mph=np.mean(area), mpd=len(area)/4, valley=True, threshold=-(2*np.mean(area))/3,edge='both')\n",
    "    peak_list = np.zeros(srcnpy.shape[1])\n",
    "    #print(peak_h)\n",
    "    for i in range(len(peak_h)):\n",
    "        peak_list[peak_h[i]] = 1\n",
    "    for i in range(len(peak_l)):\n",
    "        peak_list[peak_l[i]] = -1\n",
    "    #print(peak_list)\n",
    "    return area/20,peak_h,peak_l,peak_list\n",
    "\n",
    "def easy_cour(frm):\n",
    "    for i in range(len(frm)-2):\n",
    "        if frm[i+1] == 1 and frm[i+1] != -1:\n",
    "            frm[i] = frm[i+1]\n",
    "        elif frm[i+1] == -1 and frm[i+1] != 1:\n",
    "            frm[i] = frm[i+1]\n",
    "    return frm\n",
    "\n",
    "def tensor_save(tensor_pred , data_num, frame_num,title=None):\n",
    "    tensor_pred = torch.sigmoid(tensor_pred)\n",
    "    tensor_pred = torch.gt(tensor_pred, 0.5)\n",
    "    tensor_pred = tensor_pred.type(torch.float32)\n",
    "    pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = np.array(pred)\n",
    "    return pred\n",
    "\n",
    "train_mode='mtl'\n",
    "model1 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model1.load_state_dict(torch.load('./weight/mlt_weights_base.pth'),True)\n",
    "model1.train()\n",
    "model2 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "# model2.load_state_dict(torch.load('./weight/mlt_weights_constrain_only2.pth'),True)mlt_weights_constrain+cpec2\n",
    "model2.load_state_dict(torch.load('./weight/mlt_weights_constrain+cpec2.pth'),True)\n",
    "model2.train()\n",
    "size = 128\n",
    "ki = image.to(device)\n",
    "kg = label.to(device)\n",
    "kp = point.to(device)\n",
    "kf = frame.to(device)\n",
    "tp = 38+122*0 #89 38\n",
    "for i in range(tp,tp+1):\n",
    "    a = ki[i:i+1]\n",
    "    d = kg[i:i+1]\n",
    "    c = kp[i:i+1]\n",
    "    e = kf[i:i+1]\n",
    "    #plt.subplots(figsize=(15,40))\n",
    "    color_lvla = [(1,0,0),(1,0,1)]\n",
    "    with torch.no_grad():\n",
    "        b1,b2,b3,b4 = model1(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        b11,b12,b13,b14 = model2(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "d = tensor_save(d.to(torch.float32),0,1)\n",
    "b4 = tensor_save(b4.to(torch.float32),0,1)\n",
    "b14 = tensor_save(b14.to(torch.float32),0,1)\n",
    "print(d.shape,b4.shape)\n",
    "for i in range(tp,tp+1):\n",
    "    area,peak_h,peak_l,peak_list = cal_keyframe(d,i)\n",
    "    area_wc,peak_h_wc,peak_l_wc,peak_list_wc = cal_keyframe(b4,i)\n",
    "    area_hc,peak_h_hc,peak_l_hc,peak_list_hc = cal_keyframe(b14,i)\n",
    "    peak_list = np.array(peak_list)\n",
    "    peak_list = easy_cour(peak_list)\n",
    "    plt.rcParams['axes.facecolor']='white'\n",
    "    plt.subplots(1, 1, figsize=(10, 8))\n",
    "    # plt.stem(peak_list)\n",
    "    # plt.plot(peak_list,color = 'b',linewidth = 2,linestyle = '-.')\n",
    "    plt.plot(area,color = 'purple',linewidth = 4,linestyle = '-.',label='Ground Truth')\n",
    "    plt.plot(area_wc,color = 'red',linewidth = 4,linestyle = '--',label='w/o CSC')\n",
    "    plt.plot(area_hc,color = 'green',linewidth = 4,linestyle = '-',label='Our Method')\n",
    "    # plt.scatter(range(30),peak_list,marker='o',s=52,c='magenta',edgecolor='magenta')\n",
    "    # plt.scatter(range(30),area,marker='o',s=92,c='magenta',edgecolor='b',facecolor='black')\n",
    "    plt.grid('on')\n",
    "    plt.legend(loc=\"upper right\",fontsize=30)\n",
    "    plt.ylim([min(area)-(0.3)*(abs(min(area))),max(area)+(0.6)*(abs(min(area)))])\n",
    "    # plt.set_facecolor('greenyellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model1 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model1.load_state_dict(torch.load('./weight/mlt_weights_base.pth'),True)\n",
    "model1.train()\n",
    "model2 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model2.load_state_dict(torch.load('./weight/mlt_weights_constrain_only2.pth'),True)\n",
    "model2.train()\n",
    "size = 128\n",
    "ki = image.to(device)\n",
    "kg = label.to(device)\n",
    "kp = point.to(device)\n",
    "kf = frame.to(device)\n",
    "tp = 5+80*2\n",
    "for i in range(tp,tp+1):\n",
    "    a = ki[i:i+1]\n",
    "    d = kg[i:i+1]\n",
    "    c = kp[i:i+1]\n",
    "    e = kf[i:i+1]\n",
    "    #plt.subplots(figsize=(15,40))\n",
    "    color_lvla = [(1,0,0),(0,1,0)]\n",
    "    with torch.no_grad():\n",
    "        b1,b2,b3,b4 = model1(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        b11,b12,b13,b14 = model2(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        for k in range(6):\n",
    "            j = k\n",
    "            plt.subplots(figsize=(15,20),constrained_layout=True)\n",
    "            plt.subplot(141)\n",
    "            # print('imshape',ims.shape)\n",
    "            img = ims[i,j,:,:,0]\n",
    "            alp,bet = 53,11\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "            plt.axis('off')\n",
    "            image_ori = np.zeros((128,128,3),dtype=int)\n",
    "            image_ori[:,:,0] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,1] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,2] = (img*alp+bet)[:,:]\n",
    "            plt.subplot(142)\n",
    "            # print(d.shape)\n",
    "            gt = tensor_save(d[0,j,0,:,:].to(torch.float32),0,1)\n",
    "            gt = apply_mask(image_ori,gt,color_lvla[1])\n",
    "            b1map = point_image(locmap1(np.array(c.cpu()))[0,j,:,:],gt)\n",
    "            plt.imshow(b1map)\n",
    "            # plt.imshow(gt)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(143)\n",
    "            pred = tensor_save(b14[0,j,0,:,:].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            b11map = point_image(locmap1(np.array(b11.cpu()))[0,j,:,:],pred)\n",
    "            plt.imshow(b11map)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(144)\n",
    "            pred = tensor_save(b4[0,j,0,:,:].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            b1map = point_image(locmap1(np.array(b1.cpu()))[0,j,:,:],pred)\n",
    "            plt.imshow(b1map)\n",
    "            # plt.imshow(pred)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode='mtl'\n",
    "device = torch.device(\"cuda\")\n",
    "model1 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model1.load_state_dict(torch.load('./weight/mlt_weights_base.pth'),True)\n",
    "model1.train()\n",
    "model2 = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "model2.load_state_dict(torch.load('./weight/mlt_weights_constrain_only2.pth'),True)\n",
    "model2.train()\n",
    "size = 128\n",
    "ki = image.to(device)\n",
    "kg = label.to(device)\n",
    "kp = point.to(device)\n",
    "kf = frame.to(device)\n",
    "tp = 45+122*2\n",
    "for i in range(tp,tp+10):\n",
    "    a = ki[i:i+1]\n",
    "    d = kg[i:i+1]\n",
    "    c = kp[i:i+1]\n",
    "    e = kf[i:i+1]\n",
    "    #plt.subplots(figsize=(15,40))\n",
    "    color_lvla = [(1,0,0),(0,1,0)]\n",
    "    with torch.no_grad():\n",
    "        b1,b2,b3,b4 = model1(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        b11,b12,b13,b14 = model2(a)#x_pot,x_potmap,x_frm,x_seg\n",
    "        for k in range(1):\n",
    "            j = k\n",
    "            plt.subplots(figsize=(15,20),constrained_layout=True)\n",
    "            plt.subplot(141)\n",
    "            # print('imshape',ims.shape)\n",
    "            img = ims[i,j,:,:,0]\n",
    "            alp,bet = 53,11\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "            plt.axis('off')\n",
    "            image_ori = np.zeros((128,128,3),dtype=int)\n",
    "            image_ori[:,:,0] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,1] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,2] = (img*alp+bet)[:,:]\n",
    "            plt.subplot(142)\n",
    "            # print(d.shape)\n",
    "            gt = tensor_save(d[0,j,0,:,:].to(torch.float32),0,1)\n",
    "            gt = apply_mask(image_ori,gt,color_lvla[1])\n",
    "            # b1map = point_image(locmap1(np.array(c.cpu()))[0,j,:,:],gt)\n",
    "            # plt.imshow(b1map)\n",
    "            plt.imshow(gt)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(143)\n",
    "            pred = tensor_save(b14[0,j,0,:,:].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            # b11map = point_image(locmap1(np.array(b11.cpu()))[0,j,:,:],pred)\n",
    "            # plt.imshow(b11map)\n",
    "            plt.imshow(pred)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(144)\n",
    "            pred = tensor_save(b4[0,j,0,:,:].to(torch.float32),0,1)\n",
    "            pred = apply_mask(image_ori,pred,color_lvla[1])\n",
    "            # b1map = point_image(locmap1(np.array(b1.cpu()))[0,j,:,:],pred)\n",
    "            # plt.imshow(b1map)\n",
    "            plt.imshow(pred)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
