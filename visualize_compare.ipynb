{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import math\n",
    "    \n",
    "class CoPreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x,x1, **kwargs):\n",
    "        return self.fn(self.norm(x),self.norm(x1), **kwargs)\n",
    "\n",
    "class CoAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x,x1):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "        qkv1 = self.to_qkv(x1).chunk(3, dim = -1)\n",
    "        q1, k1, v1 = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv1)\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k1) * self.scale\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "        \n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v1)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class CoTransformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                CoPreNorm(dim, CoAttention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))]))\n",
    "\n",
    "    def forward(self, x,x1):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x,x1) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)\n",
    "    \n",
    "class cosa(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = in_channels * patch_size ** 2\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b t c (h p1) (w p2) -> b (t c) (h w) (p1 p2)', p1 = patch_size, p2 = patch_size),\n",
    "        )\n",
    "        self.pos_embedding = PositionalEmbedding(num_patches*patch_size**2)\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.transformer = CoTransformer(patch_size**2, depth, heads, dim_head, dim*scale_dim, dropout)\n",
    "        self.img_out = image_size\n",
    "        self.time = num_frames\n",
    "        self.channel = in_channels\n",
    "        self.patch_size = patch_size\n",
    "    def forward(self, x1,x2):\n",
    "        x1,x2 = rearrange(x1, 'b c t n d -> b t c n d'), rearrange(x2, 'b c t n d -> b t c n d')\n",
    "        x1,x2 = self.to_patch_embedding(x1),self.to_patch_embedding(x2)\n",
    "        b, t, n, d = x1.shape\n",
    "        pos1,pos2 = self.pos_embedding(x1,n,d),self.pos_embedding(x2,n,d)\n",
    "        x1 = x1 + pos1\n",
    "        x2 = x2 + pos2\n",
    "        x1 = rearrange(x1, 'b t n d -> (b t) n d')\n",
    "        x2 = rearrange(x2, 'b t n d -> (b t) n d')\n",
    "        x = self.transformer(x1,x2)\n",
    "        patch_height = int(self.img_out/self.patch_size)\n",
    "        x = rearrange(x, '(t c) (ph pw) (p1 p2) -> t c (ph p1) (pw p2)', t = self.time, c = self.channel,\n",
    "                      ph = patch_height, p1 = self.patch_size)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = rearrange(x, 'b t c n d -> b c t n d')\n",
    "        return x\n",
    "    \n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x_attn = attn(x) \n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x),self.norm(x_attn)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, demb):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "\n",
    "        self.demb = demb\n",
    "        self.mlp = nn.Sequential(nn.LayerNorm(self.demb),nn.Linear(self.demb, 1))\n",
    "        inv_freq = 1 / (10 ** (torch.arange(0.0, demb, 2.0) / demb))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, pos_seq,imgsize,imgdim, bsz=None):\n",
    "        pos_seq = rearrange(pos_seq, 'b t n d -> b t (n d)')\n",
    "        pos_seq = self.mlp(pos_seq)\n",
    "        pos_seq = pos_seq.squeeze(0)\n",
    "        pos_seq = pos_seq.squeeze(1)\n",
    "        #print(pos_seq)\n",
    "        sinusoid_inp = torch.ger(pos_seq, self.inv_freq)\n",
    "        pos_emb = torch.cat([torch.sin(sinusoid_inp), torch.cos(sinusoid_inp)], dim=-1)\n",
    "        if bsz is not None:\n",
    "            pos_emb = pos_emb[:,None,:].expand(-1, bsz, -1)\n",
    "        else:\n",
    "            pos_emb = pos_emb[:,None,:]\n",
    "        #print(pos_emb.shape)\n",
    "        pos_emb = rearrange(pos_emb, 't b (n d) -> b t n d',n=imgsize,d=imgdim)\n",
    "        return pos_emb\n",
    "    \n",
    "class STFH(nn.Module):\n",
    "    def __init__(self, image_size,patch_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = in_channels * patch_size ** 2\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b t c (h p1) (w p2) -> b (t c) (h w) (p1 p2)', p1 = patch_size, p2 = patch_size),\n",
    "        )\n",
    "        self.pos_embedding = PositionalEmbedding(num_patches*patch_size**2)\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.spatio_temporal_transformer = Transformer(patch_size**2, depth, heads, dim_head, dim*scale_dim, dropout)\n",
    "        self.img_out = image_size\n",
    "        self.time = num_frames\n",
    "        self.channel = in_channels\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "       \n",
    "    def forward(self, x):\n",
    "        #print('before p_emb',x.shape)\n",
    "        theta = 5\n",
    "        pool = nn.MaxPool3d(kernel_size=theta, stride=1, padding=(theta - 1) // 2)\n",
    "        x_pool = pool(x)\n",
    "        x = 2*x - x_pool\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        x = self.to_patch_embedding(x)\n",
    "        b, t, n, d = x.shape\n",
    "        pos = self.pos_embedding(x,n,d)\n",
    "        x = x + pos\n",
    "        x = self.dropout(x)\n",
    "        x = rearrange(x, 'b t n d -> (b t) n d')\n",
    "        x,x_att = self.spatio_temporal_transformer(x)\n",
    "        patch_height = int(self.img_out/self.patch_size)\n",
    "        x = rearrange(x, '(t c) (ph pw) (p1 p2) -> t c (ph p1) (pw p2)', t = self.time, c = self.channel,\n",
    "                      ph = patch_height, p1 = self.patch_size)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = rearrange(x, 'b t c n d -> b c t n d')\n",
    "        x_att = rearrange(x_att, '(t c) (ph pw) (p1 p2) -> t c (ph p1) (pw p2)', t = self.time, c = self.channel,\n",
    "                      ph = patch_height, p1 = self.patch_size)\n",
    "        x_att = x_att.unsqueeze(0)\n",
    "        x_att = rearrange(x_att, 'b t c n d -> b c t n d')\n",
    "        return x,x_att\n",
    "    \n",
    "class Dual_path(nn.Module):\n",
    "    def __init__(self, image_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        #assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        #num_patches = (image_size // patch_size) ** 2\n",
    "        #patch_dim = in_channels * patch_size ** 2\n",
    "        self.spatio_stfh = STFH(image_size=image_size, patch_size=image_size//2, in_channels=in_channels ,num_frames=num_frames)\n",
    "        self.temporal_stfh = STFH(image_size=image_size, patch_size=image_size, in_channels=in_channels ,num_frames=num_frames)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #print('before p_emb',x.shape)\n",
    "        theta = 5\n",
    "        pool = nn.MaxPool3d(kernel_size=theta, stride=1, padding=(theta - 1) // 2)\n",
    "        x_pool = pool(x)\n",
    "        x_bound = 2*x - x_pool\n",
    "        x_bound,x_att_b = self.spatio_stfh(x_bound)\n",
    "        x,x_att_t = self.temporal_stfh(x)\n",
    "        x_croatt = x_att_t*x_att_b\n",
    "        x = x+x_bound+x_croatt\n",
    "        return x\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer, time_steps):        \n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.layers = nn.ModuleList([layer for i in range(time_steps)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        batch_size, time_steps, C, H, W = x.size()\n",
    "        output = torch.tensor([]).cuda()\n",
    "        #output = torch.tensor([])\n",
    "        for i in range(time_steps):\n",
    "            output_t = self.layers[i](x[:, i, :, :, :])\n",
    "            output_t  = output_t.unsqueeze(1)\n",
    "            output = torch.cat((output, output_t ), 1)\n",
    "        output = rearrange(output, 'b t c n d -> b c t n d')\n",
    "        return output\n",
    "\n",
    "\n",
    "class EncoderBottleneck3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, base_width=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=[1,2,2], bias=False),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "        )\n",
    "\n",
    "        width = int(out_channels * (base_width / 64))\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(width, width, kernel_size=3, stride=[1,2,2], groups=1, padding=1, dilation=1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(width, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_down = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = x + x_down\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim,seq_frame):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=7, stride=[1,2,2], padding=3, bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.encoder1 = EncoderBottleneck3d(out_channels, out_channels * 2, stride=2)\n",
    "        self.encoder2 = EncoderBottleneck3d(out_channels * 2, out_channels * 4, stride=2)\n",
    "        self.encoder3 = EncoderBottleneck3d(out_channels * 4, out_channels * 8, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(out_channels * 8, out_channels * 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm2 = nn.BatchNorm3d(out_channels * 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b t c n d -> b c t n d')\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x1 = self.relu(x)\n",
    "        x2 = self.encoder1(x1)\n",
    "        x3 = self.encoder2(x2)\n",
    "        x = self.encoder3(x3)\n",
    "        #x = rearrange(x, \"b t (h w) c ->b t c h w\",h = 8, w=8)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "        #x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        #x1_out = rearrange(x1_out, 'b c t n d -> b t c n d')\n",
    "        #x2_out = rearrange(x2_out, 'b c t n d -> b t c n d')\n",
    "        #x3_out = rearrange(x3_out, 'b c t n d -> b t c n d')\n",
    "        return x, x1, x2, x3\n",
    "\n",
    "class DecoderBottleneck3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,seq_frame, scale_factor=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = TimeDistributed(nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=True), time_steps = seq_frame)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False))\n",
    "\n",
    "    def forward(self, x, x_concat=None):\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "\n",
    "        if x_concat is not None:\n",
    "            x = torch.cat([x_concat, x], dim=1)\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "class dconv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,d_rate, stride=1, base_width=64):\n",
    "        super().__init__()\n",
    "\n",
    "        width = int(out_channels * (base_width / 64))\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(width, width, kernel_size=3, stride=[1,1,1], groups=1, padding=d_rate, dilation=d_rate, bias=False)\n",
    "        self.norm2 = nn.BatchNorm3d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(width, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class task_specific_decoder(nn.Module):\n",
    "    def __init__(self, out_channels, class_num, drop_rate,seq_frame):\n",
    "        super().__init__()\n",
    "        self.d_rate = drop_rate\n",
    "        self.decoder1 = DecoderBottleneck3d(out_channels * 8, out_channels * 2,seq_frame)\n",
    "        self.decoder2 = DecoderBottleneck3d(out_channels * 4, out_channels,seq_frame)\n",
    "        self.dropout = TimeDistributed(torch.nn.Dropout(p=self.d_rate),time_steps = seq_frame)\n",
    "        \n",
    "    def forward(self, x, x2, x3):\n",
    "        x = self.decoder1(x, x3)\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder2(x, x2)\n",
    "        #x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        return x\n",
    "\n",
    "    \n",
    "class segment_head(nn.Module):\n",
    "    def __init__(self, out_channels, class_num, drop_rate,seq_frame):\n",
    "        super().__init__()\n",
    "        self.decoder3 = DecoderBottleneck3d(out_channels * 2, int(out_channels * 1 / 2),seq_frame)\n",
    "        self.decoder4 = DecoderBottleneck3d(int(out_channels * 1 / 2), int(out_channels * 1 / 8),seq_frame)\n",
    "        self.conv1 = nn.Conv3d(int(out_channels * 1 / 8), class_num, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, x1):\n",
    "        x = self.decoder3(x, x1)\n",
    "        x = self.decoder4(x)\n",
    "        x = self.conv1(x)\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        return x\n",
    "\n",
    "class point_head(nn.Module):\n",
    "    def __init__(self, out_channels, class_num, seq_frame,height,weight):\n",
    "        super().__init__()\n",
    "        self.seq_frame = seq_frame\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        self.decoder3 = DecoderBottleneck3d(out_channels * 2, int(out_channels * 1 / 2),seq_frame)\n",
    "        self.decoder4 = DecoderBottleneck3d(int(out_channels * 1 / 2), int(out_channels * 1 / 8),seq_frame)\n",
    "        self.conv1 = nn.Conv3d(int(out_channels * 1 / 8), class_num, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(class_num,1, kernel_size=1)\n",
    "        self.mlp_out = nn.Sequential(\n",
    "            nn.LayerNorm(self.height*self.weight),\n",
    "            nn.Linear(self.height*self.weight, 2))\n",
    "        \n",
    "    def forward(self, x, x1):\n",
    "        x = self.decoder3(x, x1)\n",
    "        x = self.decoder4(x)\n",
    "        x = self.conv1(x)\n",
    "        x_map = self.conv2(x)\n",
    "        x_map = rearrange(x_map, 'b c t n d -> b t c n d')\n",
    "        x = rearrange(x, 'b c t n d -> b t c n d')\n",
    "        x_pot = rearrange(x, 'b t c n d -> b t c (n d)')\n",
    "        x_pot = self.mlp_out(x_pot)\n",
    "        return x_pot,x_map\n",
    "\n",
    "# class classifi_head(nn.Module):\n",
    "#     def __init__(self, out_channels, class_num,seq_frame):\n",
    "#         super().__init__()\n",
    "#         self.out_ch = out_channels\n",
    "#         self.class_num = class_num\n",
    "#         self.seq_frame = seq_frame\n",
    "#         self.avgpool = nn.AvgPool2d(32, stride=1)\n",
    "#         self.fc = nn.Linear(self.out_ch,self.class_num)\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "#     def forward(self,x):\n",
    "#         x = x[:,:,0,:,:]\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "    \n",
    "class frame_head(nn.Module):\n",
    "    def __init__(self, out_channels, class_num,seq_frame):\n",
    "        super().__init__()\n",
    "        self.out_ch = out_channels\n",
    "        self.class_num = class_num\n",
    "        self.seq_frame = seq_frame\n",
    "        self.dconv3d2 = dconv3d(self.out_ch*1, self.out_ch*2, d_rate = 3, stride=2)\n",
    "        self.avgpool2d2  = TimeDistributed(nn.AdaptiveAvgPool2d(8), time_steps = seq_frame)\n",
    "        self.dconv3d3 = dconv3d(self.out_ch*2, self.out_ch*4, d_rate = 2, stride=2)\n",
    "        self.avgpool2d3  = TimeDistributed(nn.AdaptiveAvgPool2d(2), time_steps = seq_frame)\n",
    "        self.dconv3d4 = dconv3d(self.out_ch*4, self.out_ch*8, d_rate = 1, stride=2)\n",
    "        self.avgpool2d4  = TimeDistributed(nn.AdaptiveAvgPool2d(1), time_steps = seq_frame)\n",
    "        self.mlp_out = nn.Sequential(\n",
    "            nn.LayerNorm(self.out_ch*8),\n",
    "            nn.Linear(self.out_ch*8, self.class_num))\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x = self.dconv3d2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool2d2(x)\n",
    "        x = self.dconv3d3(x)\n",
    "        x = self.avgpool2d3(x)\n",
    "        x = self.dconv3d4(x)\n",
    "        x = self.avgpool2d4(x)\n",
    "        #print(x.shape)\n",
    "        x = rearrange(x, 'b t c n d -> (c n d)(b t)')\n",
    "        x_reg = self.mlp_out(x)\n",
    "        x_reg.squeeze()\n",
    "        #x_reg = rearrange(x_reg, 'n s -> s n')\n",
    "        return x_reg\n",
    "    \n",
    "class TaskAttention(nn.Module):\n",
    "    def __init__(self, in_ch, ratio=16):\n",
    "        super(TaskAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv3d(in_ch*2, in_ch//16, kernel_size=1),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv3d(in_ch // 16, in_ch*2, kernel_size=1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv3 = nn.Conv3d(in_ch*2, in_ch, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm3d(in_ch)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x1,x2):\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        x = self.sigmoid(out)+x\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class pattern_strcture(nn.Module):\n",
    "    def __init__(self, image_size, in_channels ,num_frames, depth = 4, heads = 3,num_classes=1, pool = 'cls', \n",
    "                 dim = 8, dim_head = 64, dropout = 0.,emb_dropout = 0., scale_dim = 4, ):\n",
    "        super().__init__()\n",
    "        self.spatio_stfh = STFH(image_size=image_size, patch_size=image_size//4, in_channels=in_channels ,num_frames=num_frames)\n",
    "        self.ta = TaskAttention(in_channels)\n",
    "        size = 32\n",
    "        self.cosa = cosa(image_size=size,patch_size=int(size//2), in_channels=32 ,num_frames=30)\n",
    "       \n",
    "    def forward(self,x1,x2,x3):\n",
    "        # x1_sa,x_att_b1 = self.spatio_stfh(x1)\n",
    "        # #print(self.ta(x2,x3,x4).shape)\n",
    "        # x2_sa,x_att_b2 = self.spatio_stfh(x2)\n",
    "        # #print(x1.shape,x2.shape,x3.shape,x4.shape)\n",
    "        # x3_sa,x_att_b3 = self.spatio_stfh(x3)\n",
    "        # # x4_sa,x_att_b4 = self.spatio_stfh(x4)\n",
    "        # beta = 0.1\n",
    "        # # x1 = beta*self.ta(x2_sa,x3_sa)+(1-beta)*x1_sa\n",
    "        # # x2 = beta*self.ta(x1_sa,x3_sa)+(1-beta)*x2_sa\n",
    "        # # x3 = beta*self.ta(x2_sa,x1_sa)+(1-beta)*x3_sa\n",
    "        # #print(self.ta(x2_sa,x3_sa).shape,x1_sa.shape)\n",
    "        # x1 = self.cosa(beta*self.ta(x2_sa,x3_sa),(1-beta)*x1_sa)\n",
    "        # x2 = self.cosa(beta*self.ta(x1_sa,x3_sa),(1-beta)*x2_sa)\n",
    "        # x3 = self.cosa(beta*self.ta(x2_sa,x1_sa),(1-beta)*x3_sa)\n",
    "        # # x4 = beta*self.ta(x2_sa,x3_sa,x1_sa)+(1-beta)*x4_sa\n",
    "        return x1,x2,x3\n",
    "\n",
    "seq_frame = 30\n",
    "\n",
    "class Multivit_net(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim, class_num, drop_rate,seq_frame\n",
    "                 ,mode,height,weight):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(img_dim, in_channels, out_channels,\n",
    "                               head_num, mlp_dim, block_num, patch_dim,seq_frame)\n",
    "        self.seg_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        self.pot_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        self.frm_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        # self.cls_decoder = task_specific_decoder(out_channels, class_num, drop_rate,seq_frame)\n",
    "        self.seg_head = segment_head(out_channels, class_num, drop_rate,seq_frame)\n",
    "        # self.cls_head = classifi_head(out_channels, class_num=4,seq_frame=seq_frame)\n",
    "        self.pot_head = point_head(out_channels, class_num=4,seq_frame=seq_frame,height=height,weight=weight)\n",
    "        self.frm_head = frame_head(out_channels, class_num=3,seq_frame=seq_frame)\n",
    "        self.mode = mode\n",
    "        self.stps = pattern_strcture(image_size=int(img_dim/4), in_channels=out_channels ,num_frames=seq_frame)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x1, x2, x3 = self.encoder(x)\n",
    "        if self.mode == 'seg':\n",
    "            x_seg = self.seg_decoder(x, x2, x3)\n",
    "            x_seg = self.seg_head(x_seg,x1)\n",
    "            return x_seg\n",
    "        elif self.mode == 'pot':\n",
    "            x_pot = self.pot_decoder(x, x2, x3)\n",
    "            x_pot = self.pot_head(x_pot,x1)\n",
    "            return x_pot\n",
    "        elif self.mode == 'frm':\n",
    "            x_frm = self.frm_decoder(x, x2, x3)\n",
    "            x_frm = self.frm_head(x_frm)\n",
    "            return x_frm\n",
    "        # elif self.mode == 'cls':\n",
    "        #     x_cls = self.cls_decoder(x, x2, x3)\n",
    "        #     x_cls = self.cls_head(x_cls)\n",
    "            return x_cls\n",
    "        elif self.mode == 'mtl':\n",
    "            x_seg = self.seg_decoder(x, x2, x3)\n",
    "            x_pot = self.pot_decoder(x, x2, x3)\n",
    "            x_frm = self.frm_decoder(x, x2, x3)\n",
    "            # x_cls = self.cls_decoder(x, x2, x3)\n",
    "            #print(x_seg.shape)\n",
    "            x_seg,x_pot,x_frm = self.stps(x_seg,x_pot,x_frm)\n",
    "            x_seg = self.seg_head(x_seg,x1)\n",
    "            x_pot,x_potmap = self.pot_head(x_pot,x1)\n",
    "            x_frm = self.frm_head(x_frm)\n",
    "            # x_cls = self.cls_head(x_cls)\n",
    "        return x_pot,x_potmap,x_frm,x_seg\n",
    "    \n",
    "from scipy.ndimage import morphology\n",
    "def coefficients(gt, pred, smooth=1e-12):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = torch.gt(pred, 0.5)\n",
    "    pred = pred.type(torch.float32)\n",
    "    intersection = torch.sum(gt * pred)\n",
    "    gt, pred = torch.sum(gt), torch.sum(pred)\n",
    "    union = gt + pred - intersection\n",
    "\n",
    "    precision = intersection / (pred + smooth)\n",
    "    recall = intersection / (gt + smooth)\n",
    "\n",
    "    beta_square = 0.3\n",
    "    f_beta_coeff = (1 + beta_square) * precision * recall / (beta_square * precision + recall + smooth)\n",
    "    dice_coeff = (2. * intersection) / (union + intersection + smooth)\n",
    "    jaccard_coeff = intersection / (union + smooth)\n",
    "    \n",
    "    \n",
    "    return dice_coeff, jaccard_coeff, f_beta_coeff, precision, recall\n",
    "\n",
    "def acc(pred,gt):\n",
    "    right,error = 0,0\n",
    "    right_es,error_es = 0,0\n",
    "    right_ed,error_ed = 0,0\n",
    "    for i in range(30):\n",
    "        if float(gt[i:i+1]) == 0:\n",
    "            if float(gt[i:i+1]) == float(torch.max(pred[i:i+1], 1)[1]):\n",
    "                    right_es = right_es+1\n",
    "            else:\n",
    "                    error_es = error_es+1\n",
    "        elif float(gt[i:i+1]) == 1:\n",
    "            if float(gt[i:i+1]) == float(torch.max(pred[i:i+1], 1)[1]):\n",
    "                    right = right+1\n",
    "            else:\n",
    "                    error = error+1\n",
    "        elif float(gt[i:i+1]) == 2:\n",
    "            if float(gt[i:i+1]) == float(torch.max(pred[i:i+1], 1)[1]):\n",
    "                    right_ed = right_ed+1\n",
    "            else:\n",
    "                    error_ed = error_ed+1\n",
    "    return right/(right+error),right_es/(right_es+error_es+0.002),right_ed/(right_ed+error_ed+0.002)\n",
    "    \n",
    "\n",
    "def get_hausdorff(gt, pred, sampling=0.3, connectivity=1):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = torch.gt(pred, 0.5)\n",
    "    input1 = gt\n",
    "    input2 = pred\n",
    "    input1 = np.array(input1.cpu().clone()) \n",
    "    input2 = np.array(input2.cpu().clone()) \n",
    "    input_1 = np.atleast_1d(input1.astype(np.bool))\n",
    "    input_2 = np.atleast_1d(input2.astype(np.bool))\n",
    "\n",
    "    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n",
    "\n",
    "    S = input_1 ^ morphology.binary_erosion(input_1, conn)\n",
    "    Sprime = input_2 ^ morphology.binary_erosion(input_2, conn)\n",
    "\n",
    "    dta = morphology.distance_transform_edt(~S, sampling)\n",
    "    dtb = morphology.distance_transform_edt(~Sprime, sampling)\n",
    "\n",
    "    sds = np.concatenate([np.ravel(dta[Sprime != 0]), np.ravel(dtb[S != 0])])\n",
    "    hausdorff_distance = sds.max()\n",
    "    mean_abs_distance = np.abs(sds).mean()\n",
    "    return hausdorff_distance, mean_abs_distance\n",
    "    \n",
    "def seg_loss(y_pred,y_true):\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    smooth       = 1e-12\n",
    "    y_true_back  = 1 - y_true\n",
    "    y_pred_back  = 1 - y_pred\n",
    "    alpha        = 1 / (torch.pow(torch.sum(y_true), 2) + smooth)\n",
    "    beta         = 1 / (torch.pow(torch.sum(y_true_back), 2) + smooth)\n",
    "    numerater    = alpha * torch.sum(y_true * y_pred) + beta * torch.sum(y_true_back * y_pred_back)\n",
    "    denominator  = alpha * torch.sum(y_true + y_pred) + beta * torch.sum(y_true_back + y_pred_back)\n",
    "    dice_loss    = 1 - (2. * numerater) / (denominator + smooth)\n",
    "    mae_loss     = torch.mean(torch.log(1 + torch.exp(torch.abs(y_pred - y_true))))\n",
    "    w            = (img_size * img_size - torch.sum(y_pred)) / (torch.sum(y_pred) + smooth)\n",
    "    key_w        = 0.003\n",
    "    crossentropy = - torch.mean(key_w * w * y_true * torch.log(y_pred + smooth) + y_true_back * torch.log(y_pred_back + smooth))\n",
    "    #print(crossentropy)\n",
    "    return crossentropy + dice_loss + mae_loss\n",
    "\n",
    "def one_hot(label, n_classes, requires_grad=True):\n",
    "    \"\"\"Return One Hot Label\"\"\"\n",
    "    divce = label.device\n",
    "    one_hot_label = torch.eye(n_classes, device=device, requires_grad=requires_grad)[label]\n",
    "    one_hot_label = one_hot_label.transpose(1, 3).transpose(2, 3)\n",
    "    return one_hot_label\n",
    "\n",
    "def boundary_cos_loss(gt , pred):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    #gt dimension (B,T,C,H,W)\n",
    "    b,t,c,h,w = gt.shape\n",
    "    for i in range(t):\n",
    "        gt_frame = gt[0,i:i+1,:,:,:]\n",
    "        pred_frame = pred[0,i:i+1,:,:,:]\n",
    "        theta0 = 3\n",
    "        gt_cont = F.max_pool2d(1 - gt_frame, kernel_size=theta0, stride=1, padding=(theta0 - 1) // 2)\n",
    "        gt_cont -= 1 - gt_frame\n",
    "        pred_cont = F.max_pool2d(1 - pred_frame, kernel_size=theta0, stride=1, padding=(theta0 - 1) // 2)\n",
    "        pred_cont -= 1 - pred_frame\n",
    "        sim = torch.cosine_similarity(gt_cont.squeeze(0).squeeze(0),pred_cont.squeeze(0).squeeze(0))\n",
    "        sim_norm = torch.sum(sim)/(h)\n",
    "        sim_loss = 1 - sim_norm*2\n",
    "        if i == 0:\n",
    "            loss = sim_loss\n",
    "        else:\n",
    "            loss = loss + sim_loss\n",
    "    return loss / t\n",
    "\n",
    "def cos_sim_loss(gt , pred):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    #gt dimension (B,T,C,H,W)\n",
    "    b,t,c,h,w = gt.shape\n",
    "    for i in range(t):\n",
    "        gt_frame = gt[0,i:i+1,:,:,:]\n",
    "        pred_frame = pred[0,i:i+1,:,:,:]\n",
    "        theta0 = 3\n",
    "        sim = torch.cosine_similarity(gt_frame.squeeze(0).squeeze(0),pred_frame.squeeze(0).squeeze(0))\n",
    "        sim_norm = torch.sum(sim)/(h)\n",
    "        sim_loss = 1 - sim_norm*2\n",
    "        if i == 0:\n",
    "            loss = sim_loss\n",
    "        else:\n",
    "            loss = loss + sim_loss\n",
    "    return loss / t\n",
    "\n",
    "def corr_loss(pred,gt):\n",
    "    pred_lva,pred_mvd,pred_lvd = pred[0,:],pred[1,:],pred[2,:]\n",
    "    gt_lva,  gt_mvd,  gt_lvd   = gt[0,:],  gt[1,:],  gt[2,:]\n",
    "    pred,gt = pred_lva, gt_lva\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lva = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / ((\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2)))+1e-12)\n",
    "    pred,gt = pred_mvd, gt_mvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_mvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / ((\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2)))+1e-12)\n",
    "    pred,gt = pred_lvd, gt_lvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / ((\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2)))+1e-12)\n",
    "    #print('corr1:',corr_lva,'corr2:',corr_mvd,'corr3:',corr_lvd)\n",
    "    corr = corr_lva+2*corr_mvd+2*corr_lvd+1e-12\n",
    "    return 5-corr\n",
    "\n",
    "def mae_loss(pred,gt):\n",
    "    mae1 = torch.mean(torch.abs(pred[0,:]-gt[0,:]))\n",
    "    mae2 = torch.mean(torch.abs(pred[1,:]-gt[1,:]))\n",
    "    mae3 = torch.mean(torch.abs(pred[2,:]-gt[2,:]))\n",
    "    mae = mae2+mae3*2\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    #logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    mae_mean = torch.mean(torch.abs(torch.mean(pred)-torch.mean(gt)))\n",
    "    return mae\n",
    "\n",
    "def mae_point(pred,gt):\n",
    "    mae = torch.mean(torch.abs(pred-gt))\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    return mae\n",
    "\n",
    "def mae_cal(pred,gt):\n",
    "    mae1 = torch.mean(torch.abs(pred[0,:]-gt[0,:]))\n",
    "    mae2 = torch.mean(torch.abs(pred[1,:]-gt[1,:]))\n",
    "    mae3 = torch.mean(torch.abs(pred[2,:]-gt[2,:]))\n",
    "    mae = mae2+mae3*2\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def person_corr(pred, gt):#皮尔森相关系数\n",
    "    pred_lva,pred_mvd,pred_lvd = pred[0,:],pred[1,:],pred[2,:]\n",
    "    gt_lva,  gt_mvd,  gt_lvd   = gt[0,:],  gt[1,:],  gt[2,:]\n",
    "    pred,gt = pred_lva, gt_lva\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lva = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / (\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2))+1e-12)\n",
    "    pred,gt = pred_mvd, gt_mvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_mvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / (\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2))+1e-12)\n",
    "    pred,gt = pred_lvd, gt_lvd\n",
    "    pred_mean, gt_mean = torch.mean(pred), torch.mean(gt)\n",
    "    corr_lvd = (torch.sum((pred - pred_mean) * (gt - gt_mean))) / (\n",
    "                torch.sqrt(torch.sum((pred - pred_mean) ** 2)) * torch.sqrt(torch.sum((gt - gt_mean) ** 2))+1e-12)\n",
    "    return corr_lva, corr_mvd,corr_lvd\n",
    "\n",
    "\n",
    "def point2linear(point):\n",
    "    mvdt = []\n",
    "    lvdt = []\n",
    "    #point:1,30,4,2\n",
    "    for t in range(30):\n",
    "        mvd = ((point[t,0,0]-point[t,1,0])**2+(point[t,0,1]-point[t,1,1])**2)**(1/2)\n",
    "        lvd = ((point[t,2,0]-point[t,3,0])**2+(point[t,2,1]-point[t,3,1])**2)**(1/2)\n",
    "        mvdt.append(mvd)\n",
    "        lvdt.append(lvd)\n",
    "        if t>0:\n",
    "            if mvdt[t]<mvdt[t-1]*0.6:\n",
    "                mvdt[t] = mvdt[t-1]\n",
    "            # elif mvdt[t]>mvdt[t-1]*1.8:\n",
    "            #     mvdt[t] = mvdt[t-1]\n",
    "    return mvdt,lvdt\n",
    "\n",
    "def pot2index(srcnpy):\n",
    "    mvd_gt,lvd_gt  = [],[]\n",
    "    # print(srcnpy.shape)#1,30,4,2\n",
    "    # for i in range(srcnpy.shape[0]):\n",
    "    mvd1,lvd1 = point2linear(srcnpy[0])\n",
    "    mvd_gt.append(mvd1)\n",
    "    lvd_gt.append(lvd1)\n",
    "    #print(lvd,lvd1)\n",
    "    lvd_gt = np.array(lvd_gt)[:,:,np.newaxis]\n",
    "    mvd_gt = np.array(mvd_gt)[:,:,np.newaxis]\n",
    "    index  = np.concatenate((lvd_gt, mvd_gt), axis=2)\n",
    "    return index\n",
    "\n",
    "def mae_div(pred,gt):\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "    gt = gt.cpu().detach().numpy()\n",
    "    pred_ind = pot2index(pred)\n",
    "    gt_ind   = pot2index(gt)\n",
    "    # print(gt_ind.shape)\n",
    "    mae1 = np.mean(np.abs(pred_ind[:,:,0]-gt_ind[:,:,0]))\n",
    "    mae2 = np.mean(np.abs(pred_ind[:,:,1]-gt_ind[:,:,1]))\n",
    "    mae = mae1+mae2\n",
    "    #mae = torch.mean((pred-gt)* torch.tanh(pred-gt))\n",
    "    # logcosh = torch.mean(torch.log(torch.cosh((pred-gt) + 1e-12)))\n",
    "    return mae1,mae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning set\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mode1 = 'hmc'\n",
    "mode2 = 'camus'\n",
    "mode3 = 'lm'\n",
    "mode4 = 'sz'\n",
    "mode5 = 'nature'\n",
    "\n",
    "mode = mode1\n",
    "if mode == mode1:\n",
    "    data_path = '/data/zhangzhenxuan/HMC_QU_data'\n",
    "    test_set_down = 0\n",
    "    test_set_up = 100\n",
    "    hmc_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_hmc.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    hmc_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_hmc.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    ims = hmc_a4c_ims\n",
    "    gts = hmc_a4c_gts\n",
    "    \n",
    "elif mode == mode2:\n",
    "    data_path = '/data/zhangzhenxuan/camus_data'\n",
    "    test_set_down = 0\n",
    "    test_set_up = 500\n",
    "    camus_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_camus.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    camus_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_camus.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    camus_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_camus.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    camus_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_camus.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    ims         = np.concatenate((camus_a2c_ims, camus_a4c_ims), axis=0)\n",
    "    gts         = np.concatenate((camus_a2c_gts, camus_a4c_gts), axis=0)\n",
    "    \n",
    "elif mode == mode3:\n",
    "    data_path = '/data/zhangzhenxuan/lm_data'\n",
    "    test_set_down = 0\n",
    "    test_set_up = 122\n",
    "    lm_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_lm.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    lm_a3c_ims  = np.load(data_path + '/' + 'ims_a3c_lm.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    lm_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_lm.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    lm_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_lm.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    lm_a3c_gts  = np.load(data_path + '/' + 'gts_a3c_lm.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    lm_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_lm.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    ims         = np.concatenate((lm_a2c_ims, lm_a3c_ims, lm_a4c_ims), axis=0)\n",
    "    gts         = np.concatenate((lm_a2c_gts, lm_a3c_gts, lm_a4c_gts), axis=0)\n",
    "    \n",
    "elif mode == mode4:\n",
    "    data_path = '/data/zhangzhenxuan/szkid'\n",
    "    test_set_down = 0\n",
    "    test_set_up = 100\n",
    "    sz_a2c_ims  = np.load(data_path + '/' + 'ims_a2c.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_a3c_ims  = np.load(data_path + '/' + 'ims_a3c.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_a4c_ims  = np.load(data_path + '/' + 'ims_a4c.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_asc_ims  = np.load(data_path + '/' + 'ims_asc.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_a2c_gts  = np.load(data_path + '/' + 'gts_a2c.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_a3c_gts  = np.load(data_path + '/' + 'gts_a3c.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_a4c_gts  = np.load(data_path + '/' + 'gts_a4c.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    sz_asc_gts  = np.load(data_path + '/' + 'gts_asc.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    ims         = np.concatenate((sz_a2c_ims, sz_a3c_ims, sz_a4c_ims, sz_asc_ims), axis=0)\n",
    "    gts         = np.concatenate((sz_a2c_gts, sz_a3c_gts, sz_a4c_gts, sz_asc_gts), axis=0)\n",
    "    \n",
    "if mode == mode5:\n",
    "    data_path = '/data/zhangzhenxuan/nature_data'\n",
    "    test_set_down = 0\n",
    "    test_set_up = 1990\n",
    "    nat_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_1.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    nat_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_1.npy')[test_set_down:test_set_up, :, :, :, np.newaxis]\n",
    "    ims = nat_a4c_ims\n",
    "    gts = nat_a4c_gts\n",
    "\n",
    "\n",
    "# ims         = camus_a4c_ims\n",
    "# gts         = camus_a4c_gts\n",
    "print(ims.shape, gts.shape)\n",
    "#ims = ims[:,:,:,:,:]\n",
    "#gts = gts[1:91,:,:,:,:]\n",
    "image = torch.from_numpy(ims)\n",
    "image = image.permute(0, 1, 4, 2, 3)\n",
    "label = torch.from_numpy(gts)\n",
    "label = label.permute(0, 1, 4, 2, 3)\n",
    "print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch import nn, optim\n",
    "import timeit\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "unloader = transforms.ToPILImage()\n",
    "\n",
    "def tensor_save(tensor_pred , data_num, frame_num,title=None):\n",
    "    tensor_pred = torch.sigmoid(tensor_pred)\n",
    "    tensor_pred = torch.gt(tensor_pred, 0.5)\n",
    "    tensor_pred = tensor_pred.type(torch.float32)\n",
    "    pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = unloader(pred)\n",
    "    pred = np.array(pred)\n",
    "    # pred = fill_contour(pred)\n",
    "    #plt.imshow(pred)\n",
    "    return pred\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.2):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = cv2.Canny(mask.astype(np.uint8),0,1)\n",
    "    kernel = np.ones((1, 1), dtype=np.uint8)\n",
    "    mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= 0.5,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= 0.5,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def apply_error(image, mask, color,balance, alpha=0.9):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = mask\n",
    "    # plt.imshow(mask_out)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= balance,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= balance,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "color_lvla = [(1,0,0.5),(0,1,0),(1,1,0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for t in range(1):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [25, 30], 0.1)\n",
    "    lens = image.shape[0]\n",
    "    print('epoch=',t)\n",
    "    batch, dice,jcd, fb,p,r,had,mad = [],[],[],[],[],[],[],[]\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    pick_list = [22,3,5,7,9,13,17,18,20,21]\n",
    "    with torch.no_grad():\n",
    "        plt.subplots(10,3,figsize=(3,10),constrained_layout=True)\n",
    "        plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "        for i in range(10):\n",
    "            video = image[i:i+1,:,:,:,:]\n",
    "            # video = torch.cat([video, video, video], dim=1)\n",
    "            labelv = label[i:i+1,:,:,:,:]\n",
    "            _,_,_,predv = model(video)\n",
    "            t=0\n",
    "            img = ims[i,t,:,:,0]\n",
    "            alp,bet = 53,11\n",
    "            plt.subplot(10,3,3*i+1)\n",
    "            image_ori = np.zeros((128,128,3),dtype=int)\n",
    "            image_ori[:,:,0] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,1] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,2] = (img*alp+bet)[:,:]\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(10,3,3*i+2)\n",
    "            label_s = tensor_save(labelv[0,0,t,:,:].to(torch.float32),0,1)\n",
    "            label_v = apply_mask(image_ori,label_s,color_lvla[1])\n",
    "            plt.imshow(label_v)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(10,3,3*i+3)\n",
    "            pred_s = tensor_save(predv[0,0,t,:,:].to(torch.float32),0,1)\n",
    "            pred_v = apply_mask(image_ori,pred_s,color_lvla[1])\n",
    "            pred_mine = label_s-pred_s\n",
    "            pred_v = apply_error(pred_v,pred_mine,color_lvla[0],255)\n",
    "            # plt.imshow(pred_v)\n",
    "            # plt.axis('off')\n",
    "            pred_mine1 = pred_s-label_s\n",
    "            pred_v = apply_error(pred_v,pred_mine1,color_lvla[2],255)\n",
    "            plt.imshow(pred_v)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning set\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy.matlib\n",
    "def landmark(center_x,center_y,IMAGE_HEIGHT, IMAGE_WIDTH):\n",
    "    R = np.sqrt(2**2 + 2**2)\n",
    "    Gauss_map = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    # 直接利用矩阵运算实现\n",
    "    mask_x = np.matlib.repmat(center_x, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    mask_y = np.matlib.repmat(center_y, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    x1 = np.arange(IMAGE_WIDTH)\n",
    "    x_map = np.matlib.repmat(x1, IMAGE_HEIGHT, 1)\n",
    "    y1 = np.arange(IMAGE_HEIGHT)\n",
    "    y_map = np.matlib.repmat(y1, IMAGE_WIDTH, 1)\n",
    "    y_map = np.transpose(y_map)\n",
    "    Gauss_map = np.sqrt((x_map-mask_x)**2+(y_map-mask_y)**2)\n",
    "    Gauss_map = np.exp(-0.5*Gauss_map/R)\n",
    "    return Gauss_map\n",
    "\n",
    "def locmap(pot):\n",
    "    gauss_batch = []\n",
    "    for i in range(0,pot.shape[0]):\n",
    "        gauss_tp = []\n",
    "        for j in range(0,pot.shape[1]):\n",
    "            g_map1 = landmark(pot[i, j, 0, 0],pot[i, j, 0, 1],128,128)\n",
    "            g_map2 = landmark(pot[i, j, 1, 0],pot[i, j, 1, 1],128,128)\n",
    "            g_map3 = landmark(pot[i, j, 2, 0],pot[i, j, 2, 1],128,128)\n",
    "            g_map4 = landmark(pot[i, j, 3, 0],pot[i, j, 3, 1],128,128)\n",
    "            Gauss_map = (g_map1+g_map2+g_map3+g_map4)/4\n",
    "            gauss_tp.append(Gauss_map)\n",
    "        gauss_batch.append(gauss_tp)\n",
    "    gauss_batch = np.array(gauss_batch)[:, :, :, :, np.newaxis]\n",
    "    return gauss_batch\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/nature_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 1800\n",
    "nat_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_1.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "nat_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_1.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "nat_a4c_cls  = 4*np.ones((train_set_up))\n",
    "nat_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_1.npy')[train_set_down:train_set_up, :]\n",
    "nat_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_1.npy')[train_set_down:train_set_up, :]\n",
    "nat_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_1.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load nature===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/HMC_QU_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 100\n",
    "hmc_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_hmc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "hmc_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_hmc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "hmc_a4c_cls  = 4*np.ones((train_set_up))\n",
    "hmc_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_hmc.npy')[train_set_down:train_set_up, :]\n",
    "hmc_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_hmc.npy')[train_set_down:train_set_up, :]\n",
    "hmc_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_hmc.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load hmc===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/camus_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 500\n",
    "camus_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_camus.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "camus_a2c_cls  = 2*np.ones((train_set_up))\n",
    "camus_a4c_cls  = 4*np.ones((train_set_up))\n",
    "camus_a2c_pot  = np.load(data_path + '/' + 'pot_a2c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a2c_frm  = np.load(data_path + '/' + 'frm_a2c_camus.npy')[train_set_down:train_set_up, :]\n",
    "camus_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_camus.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load camus===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/lm_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 122\n",
    "lm_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a3c_ims  = np.load(data_path + '/' + 'ims_a3c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a3c_gts  = np.load(data_path + '/' + 'gts_a3c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_lm.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "lm_a2c_cls  = 2*np.ones((train_set_up))\n",
    "lm_a3c_cls  = 3*np.ones((train_set_up))\n",
    "lm_a4c_cls  = 4*np.ones((train_set_up))\n",
    "lm_a2c_pot  = np.load(data_path + '/' + 'pot_a2c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a3c_pot  = np.load(data_path + '/' + 'pot_a3c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a3c_potmap  = np.load(data_path + '/' + 'potmap_a3c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a2c_frm  = np.load(data_path + '/' + 'frm_a2c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a3c_frm  = np.load(data_path + '/' + 'frm_a3c_lm.npy')[train_set_down:train_set_up, :]\n",
    "lm_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_lm.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load lm===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/mx_data'\n",
    "train_set_down = 0\n",
    "train_set_up = 80\n",
    "mx_a2c_ims  = np.load(data_path + '/' + 'ims_a2c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a3c_ims  = np.load(data_path + '/' + 'ims_a3c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a4c_ims  = np.load(data_path + '/' + 'ims_a4c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a2c_gts  = np.load(data_path + '/' + 'gts_a2c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a3c_gts  = np.load(data_path + '/' + 'gts_a3c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a4c_gts  = np.load(data_path + '/' + 'gts_a4c_mx.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "mx_a2c_cls  = 2*np.ones((train_set_up))\n",
    "mx_a3c_cls  = 3*np.ones((train_set_up))\n",
    "mx_a4c_cls  = 4*np.ones((train_set_up))\n",
    "mx_a2c_pot  = np.load(data_path + '/' + 'pot_a2c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a3c_pot  = np.load(data_path + '/' + 'pot_a3c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a4c_pot  = np.load(data_path + '/' + 'pot_a4c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a3c_potmap  = np.load(data_path + '/' + 'potmap_a3c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a2c_frm  = np.load(data_path + '/' + 'frm_a2c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a3c_frm  = np.load(data_path + '/' + 'frm_a3c_mx.npy')[train_set_down:train_set_up, :]\n",
    "mx_a4c_frm  = np.load(data_path + '/' + 'frm_a4c_mx.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load mx===============')\n",
    "\n",
    "data_path = '/data/zhangzhenxuan/szkid'\n",
    "train_set_down = 0\n",
    "train_set_up = 80\n",
    "sz_a2c_ims  = np.load(data_path + '/' + 'ims_a2c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a3c_ims  = np.load(data_path + '/' + 'ims_a3c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a4c_ims  = np.load(data_path + '/' + 'ims_a4c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_asc_ims  = np.load(data_path + '/' + 'ims_asc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a2c_gts  = np.load(data_path + '/' + 'gts_a2c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a3c_gts  = np.load(data_path + '/' + 'gts_a3c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a4c_gts  = np.load(data_path + '/' + 'gts_a4c.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_asc_gts  = np.load(data_path + '/' + 'gts_asc.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_out_gts  = np.load(data_path + '/' + 'gts_out.npy')[train_set_down:train_set_up, :, :, :, np.newaxis]\n",
    "sz_a2c_cls  = 2*np.ones((train_set_up))\n",
    "sz_a3c_cls  = 3*np.ones((train_set_up))\n",
    "sz_a4c_cls  = 4*np.ones((train_set_up))\n",
    "sz_asc_cls  = 1*np.ones((train_set_up))\n",
    "sz_a2c_pot  = np.load(data_path + '/' + 'pot_a2c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a3c_pot  = np.load(data_path + '/' + 'pot_a3c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a4c_pot  = np.load(data_path + '/' + 'pot_a4c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a2c_potmap  = np.load(data_path + '/' + 'potmap_a2c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a3c_potmap  = np.load(data_path + '/' + 'potmap_a3c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a4c_potmap  = np.load(data_path + '/' + 'potmap_a4c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a2c_frm  = np.load(data_path + '/' + 'frm_a2c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a3c_frm  = np.load(data_path + '/' + 'frm_a3c.npy')[train_set_down:train_set_up, :]\n",
    "sz_a4c_frm  = np.load(data_path + '/' + 'frm_a4c.npy')[train_set_down:train_set_up, :]\n",
    "print('==============load sz===============')\n",
    "\n",
    "# ims         = np.concatenate((hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "#                               lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims, sz_asc_ims), axis=0)\n",
    "# gts         = np.concatenate((hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "#                               lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts, sz_out_gts), axis=0)\n",
    "# clss         = np.concatenate((hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "#                              lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls, sz_asc_cls), axis=0)\n",
    "# ims         = np.concatenate((hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "#                               lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "# gts         = np.concatenate((hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "#                               lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "# clss        = np.concatenate((hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "#                               lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "# reg         = np.concatenate((hmc_a4c_reg,camus_a2c_reg, camus_a4c_reg,mx_a2c_reg, mx_a3c_reg, mx_a4c_reg,\n",
    "#                               lm_a2c_reg, lm_a3c_reg, lm_a4c_reg,sz_a2c_reg, sz_a3c_reg, sz_a4c_reg), axis=0)\n",
    "\n",
    "data_mode = 'nat'\n",
    "if data_mode == 'psax':\n",
    "    ims         = np.concatenate((sz_a2c_ims, sz_a3c_ims, sz_a4c_ims, sz_asc_ims), axis=0)\n",
    "    gts         = np.concatenate((sz_a2c_gts, sz_a3c_gts, sz_a4c_gts, sz_out_gts), axis=0)\n",
    "    clss         = np.concatenate((sz_a2c_cls, sz_a3c_cls, sz_a4c_cls, sz_asc_cls), axis=0)\n",
    "    pot         = np.concatenate((sz_a2c_pot, sz_a3c_pot, sz_a4c_pot, sz_asc_pot), axis=0)\n",
    "    frm         = np.concatenate((sz_a2c_frm, sz_a3c_frm, sz_a4c_frm, sz_asc_frm), axis=0)\n",
    "elif data_mode == 'apic_1':\n",
    "    ims         = np.concatenate((sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "    gts         = np.concatenate((sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "    clss         = np.concatenate((sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "    pot         = np.concatenate((sz_a2c_pot, sz_a3c_pot, sz_a4c_pot), axis=0)\n",
    "    potmap      = locmap(pot)\n",
    "    frm         = np.concatenate((sz_a2c_frm, sz_a3c_frm, sz_a4c_frm), axis=0) \n",
    "elif data_mode == 'apic_2':\n",
    "    ims         = np.concatenate((hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "                                  lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "    print(ims.shape)\n",
    "    gts         = np.concatenate((hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "                                  lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "    print(gts.shape)\n",
    "    clss        = np.concatenate((hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "                                  lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "    print(clss.shape)\n",
    "    pot         = np.concatenate((hmc_a4c_pot,camus_a2c_pot, camus_a4c_pot,mx_a2c_pot, mx_a3c_pot, mx_a4c_pot,\n",
    "                                  lm_a2c_pot, lm_a3c_pot, lm_a4c_pot,sz_a2c_pot, sz_a3c_pot, sz_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((hmc_a4c_potmap,camus_a2c_potmap, camus_a4c_potmap,mx_a2c_potmap, mx_a3c_potmap, mx_a4c_potmap,\n",
    "                                  lm_a2c_potmap, lm_a3c_potmap, lm_a4c_potmap,sz_a2c_potmap, sz_a3c_potmap, sz_a4c_potmap), axis=0)\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = np.concatenate((hmc_a4c_frm,camus_a2c_frm, camus_a4c_frm,mx_a2c_frm, mx_a3c_frm, mx_a4c_frm,\n",
    "                                  lm_a2c_frm, lm_a3c_frm, lm_a4c_frm,sz_a2c_frm, sz_a3c_frm, sz_a4c_frm), axis=0) \n",
    "elif data_mode == 'nat':\n",
    "    ims         = np.concatenate((nat_a4c_ims,hmc_a4c_ims,camus_a2c_ims, camus_a4c_ims,mx_a2c_ims, mx_a3c_ims, mx_a4c_ims,\n",
    "                                  lm_a2c_ims, lm_a3c_ims, lm_a4c_ims,sz_a2c_ims, sz_a3c_ims, sz_a4c_ims), axis=0)\n",
    "    print(ims.shape)\n",
    "    gts         = np.concatenate((nat_a4c_gts,hmc_a4c_gts,camus_a2c_gts, camus_a4c_gts,mx_a2c_gts, mx_a3c_gts, mx_a4c_gts,\n",
    "                                  lm_a2c_gts, lm_a3c_gts, lm_a4c_gts,sz_a2c_gts, sz_a3c_gts, sz_a4c_gts), axis=0)\n",
    "    print(gts.shape)\n",
    "    clss        = np.concatenate((nat_a4c_cls,hmc_a4c_cls,camus_a2c_cls, camus_a4c_cls,mx_a2c_cls, mx_a3c_cls, mx_a4c_cls,\n",
    "                                  lm_a2c_cls, lm_a3c_cls, lm_a4c_cls,sz_a2c_cls, sz_a3c_cls, sz_a4c_cls), axis=0)\n",
    "    print(clss.shape)\n",
    "    pot         = np.concatenate((nat_a4c_pot,hmc_a4c_pot,camus_a2c_pot, camus_a4c_pot,mx_a2c_pot, mx_a3c_pot, mx_a4c_pot,\n",
    "                                  lm_a2c_pot, lm_a3c_pot, lm_a4c_pot,sz_a2c_pot, sz_a3c_pot, sz_a4c_pot), axis=0)\n",
    "    potmap      = np.concatenate((nat_a4c_potmap,hmc_a4c_potmap,camus_a2c_potmap, camus_a4c_potmap,mx_a2c_potmap, mx_a3c_potmap, mx_a4c_potmap,\n",
    "                                  lm_a2c_potmap, lm_a3c_potmap, lm_a4c_potmap,sz_a2c_potmap, sz_a3c_potmap, sz_a4c_potmap), axis=0)\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = np.concatenate((nat_a4c_frm,hmc_a4c_frm,camus_a2c_frm, camus_a4c_frm,mx_a2c_frm, mx_a3c_frm, mx_a4c_frm,\n",
    "                                  lm_a2c_frm, lm_a3c_frm, lm_a4c_frm,sz_a2c_frm, sz_a3c_frm, sz_a4c_frm), axis=0) \n",
    "    print(frm.shape) \n",
    "    \n",
    "elif data_mode == 'camus':\n",
    "    ims         = camus_a4c_ims\n",
    "    print(ims.shape)\n",
    "    gts         = camus_a4c_gts\n",
    "    print(gts.shape)\n",
    "    clss        = camus_a4c_cls\n",
    "    print(clss.shape)\n",
    "    pot         = camus_a4c_pot\n",
    "    potmap      = camus_a4c_potmap\n",
    "    print(pot.shape,potmap.shape)\n",
    "    #potmap      = locmap(pot)\n",
    "    frm         = camus_a4c_frm\n",
    "    print(frm.shape) \n",
    "# ims         = camus_a4c_ims\n",
    "# gts         = camus_a4c_gts\n",
    "#oe = OrdinalEncoder()\n",
    "#clss = oe.fit_transform(clss.reshape(-1, 1)).ravel()\n",
    "#clss = np.eye(4)[np.array(clss, dtype=np.int32)]\n",
    "print(ims.shape, gts.shape, clss.shape,pot.shape,potmap.shape,frm.shape)\n",
    "#ims = ims[:,:,:,:,:]\n",
    "#gts = gts[1:91,:,:,:,:]\n",
    "image = torch.from_numpy(ims)\n",
    "image = image.permute(0, 1, 4, 2, 3)\n",
    "label = torch.from_numpy(gts)\n",
    "label = label.permute(0, 1, 4, 2, 3)\n",
    "classi = torch.from_numpy(clss)\n",
    "point = torch.from_numpy(pot)\n",
    "pointmap = torch.from_numpy(potmap)\n",
    "pointmap = pointmap.permute(0, 1, 4, 2, 3)\n",
    "frame = torch.from_numpy(frm)\n",
    "print(image.shape)# 1800-1900-2400-2900-2980-3060-3140-3262-3385-3507-3587-3667-3747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch import nn, optim\n",
    "import timeit\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "unloader = transforms.ToPILImage()\n",
    "road = '/data/zhangzhenxuan/zhangzhenxuan/zhangzhenxuan/MTL_LOSS/multi-task'\n",
    "def tensor_save(tensor_pred , data_num, frame_num,title=None):\n",
    "    tensor_pred = torch.sigmoid(tensor_pred)\n",
    "    tensor_pred = torch.gt(tensor_pred, 0.5)\n",
    "    tensor_pred = tensor_pred.type(torch.float32)\n",
    "    pred = tensor_pred.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    pred = unloader(pred)\n",
    "    pred = np.array(pred)\n",
    "    # pred = fill_contour(pred)\n",
    "    #plt.imshow(pred)\n",
    "    return pred\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.4):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = cv2.Canny(mask.astype(np.uint8),0,1)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= 0.5,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= 0.5,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def apply_error(image, mask, color,balance, alpha=0.4):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = mask\n",
    "    # plt.imshow(mask_out)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= balance,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= balance,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "l_r = 0.001  #0.0002\n",
    "device = torch.device(\"cuda\")\n",
    "train_mode = 'mtl'\n",
    "model = Multivit_net(img_dim=128,in_channels=1,out_channels=32,head_num=4,mlp_dim=512,block_num=8,\n",
    "                     patch_dim=16,class_num=1,drop_rate = 0.2,seq_frame=30,mode =train_mode,height=128,weight=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=l_r)\n",
    "dice_less = 0.50\n",
    "seq_frame = 30\n",
    "img_size = 128\n",
    "# model.load_state_dict(torch.load(road+'/weight_seg/seg_weights3.pth'),True)\n",
    "model.eval()\n",
    "def apply_error(image, mask, color,balance, alpha=0.9):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    mask_out = mask\n",
    "    # plt.imshow(mask_out)\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "    mask_out = cv2.dilate(mask_out, kernel, 1)\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask >= balance,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask_out >= balance,\n",
    "                                  color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "color_lvla = [(1,0,0.5),(0,1,0),(1,1,0)]\n",
    "\n",
    "for t in range(1):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [25, 30], 0.1)\n",
    "    lens = image.shape[0]\n",
    "    print('epoch=',t)\n",
    "    batch, dice,jcd, fb,p,r,had,mad = [],[],[],[],[],[],[],[]\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    pick_list = [1,1800,1901,2401,2900,2980,3060,3140,3262,3385,3507,3587,3667]\n",
    "    with torch.no_grad():\n",
    "        plt.subplots(10,1,figsize=(1,10),constrained_layout=True)\n",
    "        plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "        for i in range(10):\n",
    "            video = image[pick_list[i]:pick_list[i]+1,:,:,:,:]\n",
    "            # video = torch.cat([video, video, video], dim=1)\n",
    "            labelv = label[pick_list[i]:pick_list[i]+1,:,:,:,:]\n",
    "            _,_,_,predv = model(video)\n",
    "            t=0\n",
    "            img = ims[pick_list[i],t,:,:,0]\n",
    "            alp,bet = 53,11\n",
    "            plt.subplot(10,1,i+1)\n",
    "            image_ori = np.zeros((128,128,3),dtype=int)\n",
    "            image_ori[:,:,0] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,1] = (img*alp+bet)[:,:]\n",
    "            image_ori[:,:,2] = (img*alp+bet)[:,:]\n",
    "            # plt.imshow(img,cmap = 'gray')\n",
    "            # plt.axis('off')\n",
    "            # plt.subplot(10,3,3*i+2)\n",
    "            label_s = tensor_save(labelv[0,0,t,:,:].to(torch.float32),0,1)\n",
    "            label_v = apply_mask(image_ori,label_s,color_lvla[1])\n",
    "            # plt.imshow(label_v)\n",
    "            # plt.axis('off')\n",
    "            # plt.subplot(10,3,3*i+3)\n",
    "            pred_s = tensor_save(predv[0,0,t,:,:].to(torch.float32),0,1)\n",
    "            pred_v = apply_mask(image_ori,pred_s,color_lvla[1])\n",
    "            pred_mine = label_s-pred_s\n",
    "            pred_v = apply_error(pred_v,pred_mine,color_lvla[0],255)\n",
    "            # plt.imshow(pred_v)\n",
    "            # plt.axis('off')\n",
    "            pred_mine1 = pred_s-label_s\n",
    "            pred_v = apply_error(pred_v,pred_mine1,color_lvla[2],255)\n",
    "            plt.imshow(pred_v)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
